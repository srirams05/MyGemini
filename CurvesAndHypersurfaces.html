<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title></title>
  <link rel="stylesheet" href="styles.css">
  </script> </head><script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>  
<body>
  <nav>
    <a href="index.html" style="display: block; text-align: center; padding: 10px; background-color: #f0f0f0; text-decoration: none; color: #333; border-radius: 5px; margin-bottom: 10px;">Back to Home</a>
    <ul>
    <li><a href="#vector-field-along-a-curve-in-a-manifold"
    id="toc-vector-field-along-a-curve-in-a-manifold">Vector Field along
    a curve in a manifold</a></li>
    <li><a
    href="#vector-field-along-a-curve-in-euclidean-space-and-representations-in-the-canonical-basis"
    id="toc-vector-field-along-a-curve-in-euclidean-space-and-representations-in-the-canonical-basis">Vector
    field along a curve in Euclidean space and representations in the
    canonical basis</a></li>
    <li><a href="#digression-into-riemannian-metric-tensor"
    id="toc-digression-into-riemannian-metric-tensor">Digression into
    Riemannian metric tensor</a></li>
    <li><a href="#arc-length-parameterization"
    id="toc-arc-length-parameterization">Arc Length
    Parameterization</a></li>
    <li><a href="#curvature-of-a-curve"
    id="toc-curvature-of-a-curve">Curvature of a curve</a></li>
    <li><a href="#covariant-derivative-1"
    id="toc-covariant-derivative-1">Covariant Derivative 1</a></li>
    <li><a href="#covariant-derivative-2"
    id="toc-covariant-derivative-2">Covariant Derivative 2</a></li>
    <li><a href="#covariant-derivative-3"
    id="toc-covariant-derivative-3">Covariant Derivative 3</a></li>
    <li><a href="#covariant-derivative-4"
    id="toc-covariant-derivative-4">Covariant Derivative 4</a></li>
    <li><a href="#covariant-derivatrive-5---product-rule"
    id="toc-covariant-derivatrive-5---product-rule">Covariant
    Derivatrive 5 - Product Rule</a></li>
    <li><a href="#covariant-derivative-6---metric-compatibility"
    id="toc-covariant-derivative-6---metric-compatibility">Covariant
    Derivative 6 - Metric compatibility</a></li>
    <li><a href="#vector-field-along-an-open-set-in-a-hypersurface"
    id="toc-vector-field-along-an-open-set-in-a-hypersurface">Vector
    Field ALONG an open set in a hypersurface</a></li>
    <li><a href="#local-coordinates-adapted-to-hypersurface"
    id="toc-local-coordinates-adapted-to-hypersurface">Local coordinates
    adapted to hypersurface</a></li>
    <li><a href="#shape-operator" id="toc-shape-operator">Shape
    Operator</a></li>
    <li><a href="#metric-on-hypersurface-m"
    id="toc-metric-on-hypersurface-m">Metric on hypersurface M</a></li>
    <li><a href="#shape-operator-2" id="toc-shape-operator-2">Shape
    Operator 2</a></li>
    </ul>
  </nav>
  <article>
    <h1 id="vector-field-along-a-curve-in-a-manifold">Vector Field along
    a curve in a manifold</h1>
    <p><strong>Let <span class="math inline">\(c: I \to M\)</span> be a
    curve, <span class="math inline">\(I \in R\)</span> and <span
    class="math inline">\(M\)</span> a smooth manifold. Let <span
    class="math inline">\(Y: I \to TM\)</span> be a smooth map such that
    <span class="math inline">\(c(t) = \pi \circ Y\)</span>. We can
    compute <span class="math inline">\(dY/dt\)</span>. What is this
    object and what space does it live in?</strong></p>
    <p>The object <span class="math inline">\(\frac{dY}{dt}\)</span>
    represents the derivative of the vector field <span
    class="math inline">\(Y\)</span> along the curve <span
    class="math inline">\(c\)</span>. It’s not simply a tangent vector;
    it’s a vector in the tangent space of the tangent bundle <span
    class="math inline">\(TM\)</span>, which is itself a manifold.</p>
    <p>Let’s break it down:</p>
    <ol type="1">
    <li><p><strong>Curve <span class="math inline">\(c\)</span> and
    Vector Field <span class="math inline">\(Y\)</span> along <span
    class="math inline">\(c\)</span></strong>: We have a curve <span
    class="math inline">\(c: I \to M\)</span>, where <span
    class="math inline">\(I\)</span> is an open interval in <span
    class="math inline">\(\mathbb{R}\)</span> and <span
    class="math inline">\(M\)</span> is a smooth manifold. The smooth
    map <span class="math inline">\(Y: I \to TM\)</span> is a vector
    field along the curve <span class="math inline">\(c\)</span>,
    meaning that <span class="math inline">\(Y(t)\)</span> is a tangent
    vector <span class="math inline">\(Y(t) \in T_{c(t)}M\)</span> at
    each <span class="math inline">\(t \in I\)</span>. The condition
    <span class="math inline">\(c(t) = \pi \circ Y(t)\)</span> means
    that the projection of the vector field <span
    class="math inline">\(Y(t)\)</span> is the point <span
    class="math inline">\(c(t)\)</span> on the curve. In other words,
    the base point of the tangent vector at each point of the curve is
    the point on the curve itself.</p></li>
    <li><p><strong>Derivative as a Vector in <span
    class="math inline">\(TTM\)</span></strong>: The derivative <span
    class="math inline">\(\frac{dY}{dt}\)</span> lives in the
    <em>tangent bundle of the tangent bundle</em>, denoted <span
    class="math inline">\(TTM\)</span>. More precisely, <span
    class="math inline">\(\frac{dY}{dt}(t) \in T_{Y(t)}(TM)\)</span>.
    This is because <span class="math inline">\(Y(t)\)</span> is a point
    in <span class="math inline">\(TM\)</span>, and the derivative of
    <span class="math inline">\(Y\)</span> with respect to <span
    class="math inline">\(t\)</span> is the velocity of the curve <span
    class="math inline">\(Y(t)\)</span> in the tangent bundle <span
    class="math inline">\(TM\)</span>. The tangent bundle itself is a
    manifold, so it has a tangent space. The derivative <span
    class="math inline">\(\frac{dY}{dt}(t)\)</span> is an element of the
    tangent space to the tangent bundle at the point <span
    class="math inline">\(Y(t)\)</span>. This is a higher order tangent
    space; it is the tangent space of the tangent bundle.</p></li>
    <li><p><strong>Local Coordinates:</strong> To understand this
    better, consider local coordinates. Let <span
    class="math inline">\((U, \varphi)\)</span> be a chart on <span
    class="math inline">\(M\)</span> with coordinates <span
    class="math inline">\((x^1, \dots, x^n)\)</span>. The tangent bundle
    <span class="math inline">\(TM\)</span> has local coordinates <span
    class="math inline">\((x^1, \dots, x^n, v^1, \dots, v^n)\)</span>,
    where <span class="math inline">\((v^1, \dots, v^n)\)</span>
    represent the components of a tangent vector in the coordinate
    basis. Then <span class="math inline">\(Y(t)\)</span> can be
    represented locally as <span class="math inline">\((x^1(t), \dots,
    x^n(t), v^1(t), \dots, v^n(t))\)</span>. The derivative is:</p>
    <p><span class="math inline">\(\frac{dY}{dt}(t) = \left(
    \frac{dx^1}{dt}(t), \dots, \frac{dx^n}{dt}(t), \frac{dv^1}{dt}(t),
    \dots, \frac{dv^n}{dt}(t) \right)\)</span></p>
    <p>Each component is a real number. This is a tangent vector in
    <span class="math inline">\(T_{Y(t)} TM\)</span>.</p></li>
    <li><p><strong>Connection:</strong> The derivative <span
    class="math inline">\(\frac{dY}{dt}\)</span> can be interpreted
    using a <em>connection</em> <span
    class="math inline">\(\nabla\)</span> on <span
    class="math inline">\(M\)</span>. The connection allows us to define
    the covariant derivative <span
    class="math inline">\(\nabla_{\gamma&#39;(t)} Y(t)\)</span> which
    can be related to <span
    class="math inline">\(\frac{dY}{dt}\)</span>. However, the
    derivative itself lives in <span class="math inline">\(TTM\)</span>
    and is not simply a tangent vector on <span
    class="math inline">\(M\)</span>.</p></li>
    </ol>
    <p>In summary, <span class="math inline">\(\frac{dY}{dt}\)</span> is
    a vector in the tangent bundle of the tangent bundle <span
    class="math inline">\(TTM\)</span>. It represents the rate of change
    of the vector field <span class="math inline">\(Y\)</span> along the
    curve <span class="math inline">\(c\)</span>, where the tangent
    vectors at each point in the curve lie on the tangent space of <span
    class="math inline">\(M\)</span>. Understanding this requires
    considering the tangent bundle as a manifold in its own right and
    utilizing the concept of tangent spaces of a tangent bundle. The use
    of a connection and covariant derivative provides further insight
    into the interpretation of this object.</p>
    <h1
    id="vector-field-along-a-curve-in-euclidean-space-and-representations-in-the-canonical-basis">Vector
    field along a curve in Euclidean space and representations in the
    canonical basis</h1>
    <p><strong>Now, let <span class="math inline">\(M = E^n\)</span>. In
    this case, we get <span class="math inline">\(T_pE^n \sim
    R^n\)</span>. Thus <span class="math inline">\(TE^n = R^n \times
    R^n\)</span>. Is this correct? What would be <span
    class="math inline">\(TTE^n\)</span>?</strong></p>
    <p>You’re right that for <span class="math inline">\(M =
    \mathbb{E}^n\)</span> (Euclidean <span
    class="math inline">\(n\)</span>-space), we can identify each
    tangent space <span class="math inline">\(T_p\mathbb{E}^n\)</span>
    with <span class="math inline">\(\mathbb{R}^n\)</span> itself. This
    identification is canonical (coordinate-independent), making
    calculations simpler. However, the statement <span
    class="math inline">\(T\mathbb{E}^n = \mathbb{R}^n \times
    \mathbb{R}^n\)</span> requires a bit more precision.</p>
    <p><strong>Tangent Bundle of <span
    class="math inline">\(\mathbb{E}^n\)</span></strong>:</p>
    <p>It’s more accurate to say that the tangent bundle <span
    class="math inline">\(T\mathbb{E}^n\)</span> is <em>isomorphic</em>
    to <span class="math inline">\(\mathbb{R}^n \times
    \mathbb{R}^n\)</span>, not exactly equal to it. The tangent bundle
    is defined as the set of pairs <span class="math inline">\((p,
    v_p)\)</span> where <span class="math inline">\(p \in
    \mathbb{E}^n\)</span> and <span class="math inline">\(v_p \in
    T_p\mathbb{E}^n\)</span>. Since <span
    class="math inline">\(T_p\mathbb{E}^n \cong \mathbb{R}^n\)</span>,
    we can identify each pair <span class="math inline">\((p,
    v_p)\)</span> with a pair <span class="math inline">\((p, v) \in
    \mathbb{R}^n \times \mathbb{R}^n\)</span>, where <span
    class="math inline">\(v\)</span> is the coordinate representation of
    <span class="math inline">\(v_p\)</span>. This identification is a
    diffeomorphism and a vector bundle isomorphism, making <span
    class="math inline">\(T\mathbb{E}^n\)</span> and <span
    class="math inline">\(\mathbb{R}^n \times \mathbb{R}^n\)</span>
    essentially equivalent for practical purposes in terms of their
    vector bundle structure.</p>
    <p><strong>Double Tangent Bundle <span
    class="math inline">\(TT\mathbb{E}^n\)</span></strong>:</p>
    <p>The double tangent bundle <span
    class="math inline">\(TT\mathbb{E}^n\)</span> is the tangent bundle
    of the tangent bundle <span
    class="math inline">\(T\mathbb{E}^n\)</span>. Since <span
    class="math inline">\(T\mathbb{E}^n \cong \mathbb{R}^n \times
    \mathbb{R}^n\)</span>, we can think of <span
    class="math inline">\(TT\mathbb{E}^n\)</span> as the tangent bundle
    of <span class="math inline">\(\mathbb{R}^n \times
    \mathbb{R}^n\)</span>. Using the same reasoning as above, <span
    class="math inline">\(TT\mathbb{E}^n\)</span> is isomorphic to:</p>
    <p><span class="math inline">\((\mathbb{R}^n \times \mathbb{R}^n)
    \times (\mathbb{R}^n \times \mathbb{R}^n) \cong \mathbb{R}^n \times
    \mathbb{R}^n \times \mathbb{R}^n \times \mathbb{R}^n \cong
    \mathbb{R}^{4n}\)</span></p>
    <p>The isomorphism arises from identifying each tangent space <span
    class="math inline">\(T_{(p, v)}(T\mathbb{E}^n)\)</span> with <span
    class="math inline">\(\mathbb{R}^n \times \mathbb{R}^n\)</span>,
    where <span class="math inline">\((p, v) \in \mathbb{R}^n \times
    \mathbb{R}^n\)</span>. Intuitively, at each point <span
    class="math inline">\((p, v)\)</span> in the tangent bundle, we have
    a tangent space that is also <span
    class="math inline">\(\mathbb{R}^n \times \mathbb{R}^n\)</span>,
    representing the possible directions of motion both in the base
    space <span class="math inline">\(\mathbb{R}^n\)</span> and in the
    fiber <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
    <p>In summary: While <span
    class="math inline">\(T\mathbb{E}^n\)</span> is <em>isomorphic</em>
    to <span class="math inline">\(\mathbb{R}^n \times
    \mathbb{R}^n\)</span>, we should not say it is equal to it.
    Similarly, <span class="math inline">\(TT\mathbb{E}^n\)</span> is
    isomorphic to <span class="math inline">\(\mathbb{R}^{4n}\)</span>.
    These isomorphisms are crucial for making calculations, but one must
    keep in mind the difference between the tangent bundle as a manifold
    and its isomorphic representation as a Cartesian product.</p>
    <p><strong>Let <span class="math inline">\(c(t): I \to E^n\)</span>
    be a smooth curve and <span class="math inline">\(Y\)</span> be the
    vector field on <span class="math inline">\(E^n\)</span> along <span
    class="math inline">\(c(t)\)</span>. Is there a way to represent
    <span class="math inline">\(Y(t)\)</span> in terms of the canonical
    basis of <span class="math inline">\(TE^n\)</span> given the
    previous answer</strong></p>
    <p>Yes, given that <span class="math inline">\(T\mathbb{E}^n \cong
    \mathbb{R}^n \times \mathbb{R}^n\)</span>, we can represent the
    vector field <span class="math inline">\(Y(t)\)</span> along the
    curve <span class="math inline">\(c(t)\)</span> in terms of the
    canonical basis of this product space. Let’s break down how:</p>
    <ol type="1">
    <li><p><strong>Curve and Vector Field:</strong> We have a smooth
    curve <span class="math inline">\(c: I \to \mathbb{E}^n\)</span>,
    where <span class="math inline">\(I\)</span> is an open interval in
    <span class="math inline">\(\mathbb{R}\)</span>. The vector field
    <span class="math inline">\(Y\)</span> along <span
    class="math inline">\(c\)</span> assigns a tangent vector <span
    class="math inline">\(Y(t) \in T_{c(t)}\mathbb{E}^n\)</span> to each
    <span class="math inline">\(t \in I\)</span>.</p></li>
    <li><p><strong>Canonical Basis of <span
    class="math inline">\(\mathbb{R}^n \times
    \mathbb{R}^n\)</span></strong>: The canonical basis for <span
    class="math inline">\(\mathbb{R}^n \times \mathbb{R}^n\)</span>
    consists of vectors of the form <span class="math inline">\((e_i,
    0)\)</span> and <span class="math inline">\((0, e_i)\)</span>, where
    <span class="math inline">\(e_i\)</span> is the <span
    class="math inline">\(i\)</span>-th standard basis vector in <span
    class="math inline">\(\mathbb{R}^n\)</span> (all zeros except for a
    1 in the <span class="math inline">\(i\)</span>-th position). There
    are <span class="math inline">\(2n\)</span> such vectors.</p></li>
    <li><p><strong>Representing <span
    class="math inline">\(c(t)\)</span>:</strong> The curve <span
    class="math inline">\(c(t)\)</span> can be represented in terms of
    the standard basis vectors of <span
    class="math inline">\(\mathbb{R}^n\)</span> as:</p>
    <p><span class="math inline">\(c(t) = \sum_{i=1}^n c^i(t)
    e_i\)</span></p>
    <p>where <span class="math inline">\(c^i(t)\)</span> are smooth
    functions giving the coordinates of <span
    class="math inline">\(c(t)\)</span> in <span
    class="math inline">\(\mathbb{R}^n\)</span>.</p></li>
    <li><p><strong>Representing <span
    class="math inline">\(Y(t)\)</span>:</strong> The tangent vector
    <span class="math inline">\(Y(t)\)</span> is an element of <span
    class="math inline">\(T_{c(t)}\mathbb{E}^n \cong
    \mathbb{R}^n\)</span>. We can express <span
    class="math inline">\(Y(t)\)</span> in terms of the standard basis
    vectors of <span class="math inline">\(\mathbb{R}^n\)</span> as:</p>
    <p><span class="math inline">\(Y(t) = \sum_{i=1}^n Y^i(t)
    e_i\)</span></p>
    <p>where <span class="math inline">\(Y^i(t)\)</span> are smooth
    functions giving the components of <span
    class="math inline">\(Y(t)\)</span> in the standard basis.</p></li>
    <li><p><strong>Representation in <span
    class="math inline">\(\mathbb{R}^n \times
    \mathbb{R}^n\)</span></strong>: To represent <span
    class="math inline">\(Y(t)\)</span> in the canonical basis of <span
    class="math inline">\(\mathbb{R}^n \times \mathbb{R}^n\)</span>, we
    combine the coordinate representation of its base point <span
    class="math inline">\(c(t)\)</span> and its components <span
    class="math inline">\(Y(t)\)</span>:</p>
    <p><span class="math inline">\(Y(t) \equiv (c(t), Y(t)) = \left(
    \sum_{i=1}^n c^i(t) e_i, \sum_{i=1}^n Y^i(t) e_i
    \right)\)</span></p>
    <p>We can write this more explicitly as a linear combination of the
    basis vectors of <span class="math inline">\(\mathbb{R}^n \times
    \mathbb{R}^n\)</span>:</p>
    <p><span class="math inline">\(Y(t) = \sum_{i=1}^n c^i(t) (e_i, 0) +
    \sum_{i=1}^n Y^i(t) (0, e_i)\)</span></p></li>
    </ol>
    <p>This shows how to express <span
    class="math inline">\(Y(t)\)</span> in terms of the canonical basis
    of <span class="math inline">\(\mathbb{R}^n \times
    \mathbb{R}^n\)</span>. The representation uses the coordinate
    functions of both the base point of the tangent vector <span
    class="math inline">\(c(t)\)</span> and the components of the
    tangent vector <span class="math inline">\(Y(t)\)</span>. The
    components <span class="math inline">\(c^i(t)\)</span> and <span
    class="math inline">\(Y^i(t)\)</span> are scalar valued smooth
    functions of <span class="math inline">\(t\)</span>.</p>
    <p><strong>Given the representations above, how to represent <span
    class="math inline">\(dY / dt\)</span> which appears to be another
    vector field?</strong></p>
    <p>Given the representation of <span
    class="math inline">\(Y(t)\)</span> in the canonical basis of <span
    class="math inline">\(\mathbb{R}^n \times \mathbb{R}^n\)</span>
    as:</p>
    <p><span class="math inline">\(Y(t) = \sum_{i=1}^n c^i(t) (e_i, 0) +
    \sum_{i=1}^n Y^i(t) (0, e_i)\)</span></p>
    <p>we can compute the derivative <span
    class="math inline">\(\frac{dY}{dt}\)</span> component-wise. This
    derivative will live in the tangent space of the tangent bundle
    <span class="math inline">\(TT\mathbb{E}^n\)</span>, which is
    isomorphic to <span class="math inline">\(\mathbb{R}^{4n}\)</span>.
    The derivative is given by:</p>
    <p><span class="math inline">\(\frac{dY}{dt}(t) = \sum_{i=1}^n
    \frac{dc^i}{dt}(t) (e_i, 0) + \sum_{i=1}^n \frac{dY^i}{dt}(t) (0,
    e_i)\)</span></p>
    <p>Here’s a breakdown:</p>
    <ol type="1">
    <li><p><strong>Derivative of Base Point:</strong> The term <span
    class="math inline">\(\sum_{i=1}^n \frac{dc^i}{dt}(t) (e_i,
    0)\)</span> represents the derivative of the base point <span
    class="math inline">\(c(t)\)</span> along the curve in <span
    class="math inline">\(\mathbb{E}^n\)</span>. It’s a vector in <span
    class="math inline">\(\mathbb{R}^n\)</span> representing the
    velocity of the base point <span
    class="math inline">\(c(t)\)</span>. Note that we can replace <span
    class="math inline">\(\sum_{i=1}^n \frac{dc^i}{dt}(t) e_i\)</span>
    with <span class="math inline">\(c&#39;(t)\)</span>.</p></li>
    <li><p><strong>Derivative of Tangent Vector Components:</strong> The
    term <span class="math inline">\(\sum_{i=1}^n \frac{dY^i}{dt}(t) (0,
    e_i)\)</span> represents the rate of change of the components of the
    tangent vector <span class="math inline">\(Y(t)\)</span> as we move
    along the curve. This is another vector in <span
    class="math inline">\(\mathbb{R}^n\)</span> that describes how the
    tangent vector itself changes.</p></li>
    <li><p><strong>Representation in <span
    class="math inline">\(TT\mathbb{E}^n\)</span></strong>: Combining
    these, we see that <span
    class="math inline">\(\frac{dY}{dt}(t)\)</span> is a vector in <span
    class="math inline">\(\mathbb{R}^n \times \mathbb{R}^n \cong
    T_{(c(t), Y(t))}(T\mathbb{E}^n)\)</span>, which represents the
    tangent space of <span class="math inline">\(T\mathbb{E}^n\)</span>
    at the point <span class="math inline">\((c(t), Y(t))\)</span>.
    Thus, <span class="math inline">\(\frac{dY}{dt}\)</span> can be
    viewed as a vector field along the curve <span
    class="math inline">\(Y(t)\)</span> on <span
    class="math inline">\(T\mathbb{E}^n\)</span>.</p></li>
    <li><p><strong>Explicit Representation:</strong> If we consider the
    canonical basis of <span
    class="math inline">\(T\mathbb{E}^n\)</span> as <span
    class="math inline">\(\{(e_i,0), (0, e_i)\}_{i=1, \dots n}\)</span>,
    we can represent <span class="math inline">\(\frac{dY}{dt}\)</span>
    as:</p>
    <p><span class="math inline">\(\frac{dY}{dt}(t) = \sum_{i=1}^n
    \frac{dc^i}{dt}(t) (e_i, 0) + \sum_{i=1}^n \frac{dY^i}{dt}(t) (0,
    e_i)\)</span></p>
    <p>This is a linear combination of the <span
    class="math inline">\(2n\)</span> basis vectors, where the
    coefficients are the time derivatives of the coordinate functions of
    the curve and of the vector field along the curve.</p></li>
    </ol>
    <p>Thus, the derivative <span
    class="math inline">\(\frac{dY}{dt}(t)\)</span> is represented as a
    vector in the tangent space of the tangent bundle <span
    class="math inline">\(TT\mathbb{E}^n\)</span>, which is isomorphic
    to <span class="math inline">\(\mathbb{R}^{4n}\)</span>. This shows
    explicitly how this derivative is a vector in <span
    class="math inline">\(TT\mathbb{E}^n\)</span>. It can be viewed as a
    vector field along the curve <span
    class="math inline">\(Y(t)\)</span> in the tangent bundle <span
    class="math inline">\(T\mathbb{E}^n\)</span>.</p>
    <h1 id="digression-into-riemannian-metric-tensor">Digression into
    Riemannian metric tensor</h1>
    <p><strong>For smooth manifold <span
    class="math inline">\(E^n\)</span>, the tangent spaces are
    isomorphic to <span class="math inline">\(R^n\)</span> which have an
    inner product defined. How does this lead to a Riemannian metric on
    <span class="math inline">\(E^n\)</span></strong></p>
    <p>The existence of an inner product on each tangent space <span
    class="math inline">\(T_p\mathbb{E}^n \cong \mathbb{R}^n\)</span> of
    Euclidean <span class="math inline">\(n\)</span>-space <span
    class="math inline">\(\mathbb{E}^n\)</span> directly leads to a
    Riemannian metric on <span
    class="math inline">\(\mathbb{E}^n\)</span>. Here’s how:</p>
    <ol type="1">
    <li><p><strong>Inner Product on Tangent Spaces:</strong> The
    standard inner product (dot product) on <span
    class="math inline">\(\mathbb{R}^n\)</span> provides an inner
    product on each tangent space <span
    class="math inline">\(T_p\mathbb{E}^n\)</span>. If <span
    class="math inline">\(v_p, w_p \in T_p\mathbb{E}^n\)</span> are two
    tangent vectors at <span class="math inline">\(p\)</span>, their
    inner product is denoted <span class="math inline">\(\langle v_p,
    w_p \rangle\)</span>. Using the canonical identification of <span
    class="math inline">\(T_p\mathbb{E}^n\)</span> with <span
    class="math inline">\(\mathbb{R}^n\)</span>, if <span
    class="math inline">\(v = (v^1, \dots, v^n)\)</span> and <span
    class="math inline">\(w = (w^1, \dots, w^n)\)</span> are the
    coordinate representations of <span
    class="math inline">\(v_p\)</span> and <span
    class="math inline">\(w_p\)</span> respectively, then the inner
    product is:</p>
    <p><span class="math inline">\(\langle v_p, w_p \rangle =
    \sum_{i=1}^n v^i w^i = v \cdot w\)</span></p></li>
    <li><p><strong>Riemannian Metric:</strong> A Riemannian metric <span
    class="math inline">\(g\)</span> on a manifold <span
    class="math inline">\(M\)</span> assigns to each point <span
    class="math inline">\(p \in M\)</span> an inner product <span
    class="math inline">\(g_p\)</span> on the tangent space <span
    class="math inline">\(T_pM\)</span>. In the case of <span
    class="math inline">\(\mathbb{E}^n\)</span>, the inner product <span
    class="math inline">\(g_p\)</span> on <span
    class="math inline">\(T_p\mathbb{E}^n\)</span> is simply the
    standard dot product inherited from <span
    class="math inline">\(\mathbb{R}^n\)</span> via the canonical
    identification. This defines the inner product at each point on the
    manifold.</p></li>
    <li><p><strong>Smoothness:</strong> The inner product is the
    standard dot product. Thus, it is smooth across the whole of <span
    class="math inline">\(\mathbb{E}^n\)</span>. Therefore the
    Riemannian metric <span class="math inline">\(g\)</span> is smooth
    across the manifold <span
    class="math inline">\(\mathbb{E}^n\)</span>. The components of the
    metric are all constant.</p></li>
    <li><p><strong>Coordinate Representation:</strong> In the standard
    coordinate system of <span
    class="math inline">\(\mathbb{E}^n\)</span>, the components of the
    metric tensor <span class="math inline">\(g_{ij}\)</span> are given
    by the Kronecker delta:</p></li>
    </ol>
    <p><span class="math inline">\(g_{ij}(p) = \delta_{ij} =
    \begin{cases} 1 &amp; i = j \\ 0 &amp; i \ne j
    \end{cases}\)</span></p>
    <p>for all <span class="math inline">\(p \in \mathbb{E}^n\)</span>.
    This is because it is the standard Euclidean metric on <span
    class="math inline">\(\mathbb{R}^n\)</span>.</p>
    <p>In summary, the standard dot product on <span
    class="math inline">\(\mathbb{R}^n\)</span>, combined with the
    canonical identification of tangent spaces with <span
    class="math inline">\(\mathbb{R}^n\)</span>, provides a smooth
    Riemannian metric on <span
    class="math inline">\(\mathbb{E}^n\)</span>. This metric defines the
    concept of lengths, angles, and distances on the manifold in a
    coordinate-independent way. The Riemannian metric is the standard
    Euclidean metric in this case. The components of the metric are
    constant everywhere on the manifold. This simplicity does not occur
    on other manifolds.</p>
    <p><strong>The inner product is a real number. Why is <span
    class="math inline">\(g_{ij}\)</span> a tensor?</strong></p>
    <p>You’re right to question this; it’s a crucial point in
    understanding Riemannian geometry. The inner product <span
    class="math inline">\(\langle v_p, w_p \rangle\)</span> at a point
    <span class="math inline">\(p\)</span> is indeed a real number.
    However, the Riemannian metric <span
    class="math inline">\(g\)</span> is not just a collection of inner
    products at each point; it’s a <em>tensor field</em> that assigns an
    inner product <em>smoothly</em> to each tangent space. The <span
    class="math inline">\(g_{ij}\)</span> are the components of this
    tensor field in a coordinate system.</p>
    <p>Here’s why <span class="math inline">\(g_{ij}\)</span> represents
    a tensor:</p>
    <ol type="1">
    <li><p><strong>Inner Product as a Bilinear Map:</strong> The inner
    product at a point <span class="math inline">\(p\)</span> can be
    viewed as a bilinear map:</p>
    <p><span class="math inline">\(g_p: T_p M \times T_p M \to
    \mathbb{R}\)</span></p>
    <p>This map takes two tangent vectors as input and produces a real
    number (the inner product). This is a tensor at the point <span
    class="math inline">\(p\)</span>.</p></li>
    <li><p><strong>Tensor Field:</strong> A Riemannian metric <span
    class="math inline">\(g\)</span> is a smooth assignment of an inner
    product to each tangent space: <span class="math inline">\(p \mapsto
    g_p\)</span>. This is a tensor <em>field</em> because it smoothly
    assigns a tensor to each point on the manifold. Smoothness is
    essential because it guarantees the well-definedness of covariant
    differentiation and other tensor operations.</p></li>
    <li><p><strong>Components in a Coordinate System:</strong> In a
    local coordinate system <span class="math inline">\((x^1, \dots,
    x^n)\)</span>, the components <span
    class="math inline">\(g_{ij}(p)\)</span> represent the inner product
    of the basis vectors at <span class="math inline">\(p\)</span>:</p>
    <p><span class="math inline">\(g_{ij}(p) = \langle
    \frac{\partial}{\partial x^i}\Big|_p, \frac{\partial}{\partial
    x^j}\Big|_p \rangle\)</span></p>
    <p>These components are smooth functions of the coordinates because
    of the smoothness of the Riemannian metric. These components
    transform correctly under a change of coordinate systems (which is
    the defining property of a tensor). This transformation is a tensor
    transformation.</p></li>
    <li><p><strong>Tensor Transformation:</strong> Under a change of
    coordinates, the components <span
    class="math inline">\(g_{ij}\)</span> transform according to the
    tensor transformation law. This means that if we change from
    coordinates <span class="math inline">\((x^1, \dots, x^n)\)</span>
    to coordinates <span class="math inline">\((x&#39;^1, \dots,
    x&#39;^n)\)</span>, the new components <span
    class="math inline">\(g&#39;_{ij}\)</span> are related to the old
    components by:</p>
    <p><span class="math inline">\(g&#39;_{ij} = \sum_{k, l}
    \frac{\partial x^k}{\partial x&#39;^i} \frac{\partial x^l}{\partial
    x&#39;^j} g_{kl}\)</span></p>
    <p>This transformation law is crucial; it ensures that the geometric
    quantity represented by the inner product remains the same
    regardless of the coordinate system used. It is coordinate
    independent.</p></li>
    </ol>
    <p>In essence, while the inner product at a point is a scalar, the
    Riemannian metric is a tensor field because it assigns inner
    products smoothly across the manifold, and the components of the
    inner product transform correctly under coordinate changes. It is
    the smooth assignment of inner products to every tangent space, and
    the transformation properties of these inner products, that make it
    a tensor.</p>
    <p><strong>The inner product which is a real number is a rank-0
    tensor. So therefore, per your previous answer, this would be a
    Riemannian metric tensor. Correct?</strong></p>
    <p>No, that’s not quite correct. While the <em>value</em> of the
    inner product at a point is a scalar (a rank-0 tensor), the
    Riemannian metric itself is not a rank-0 tensor.</p>
    <p>Here’s why:</p>
    <ul>
    <li><p><strong>Inner product at a point:</strong> The inner product
    <span class="math inline">\(\langle v, w \rangle_p\)</span> of two
    vectors <span class="math inline">\(v, w \in T_p M\)</span> at a
    <em>specific point</em> <span class="math inline">\(p\)</span> is a
    scalar (a rank-0 tensor). This scalar depends on the point and the
    vectors.</p></li>
    <li><p><strong>Riemannian metric:</strong> A Riemannian metric <span
    class="math inline">\(g\)</span> is a <em>tensor field</em> that
    assigns an inner product to each tangent space <em>smoothly</em>.
    This means that <span class="math inline">\(g\)</span> assigns a
    bilinear map <span class="math inline">\(g_p: T_p M \times T_p M \to
    \mathbb{R}\)</span> to each point <span class="math inline">\(p \in
    M\)</span>. This bilinear map is a type (0,2) tensor, not a scalar.
    It is this assignment of tensors at each point on the manifold which
    is a Riemannian metric.</p></li>
    <li><p><strong>Components of the metric tensor:</strong> The
    components <span class="math inline">\(g_{ij}(p)\)</span> in local
    coordinates represent the inner product of the basis vectors at
    <span class="math inline">\(p\)</span>: <span
    class="math inline">\(g_{ij}(p) = \langle \frac{\partial}{\partial
    x^i}, \frac{\partial}{\partial x^j} \rangle_p\)</span>. These are
    scalar valued functions, which vary smoothly across the manifold. It
    is the tensorial transformation property of the components that is
    important.</p></li>
    </ul>
    <p>The crucial distinction is between the <em>value</em> of the
    inner product (a scalar) and the <em>Riemannian metric itself</em>
    (a tensor field). The Riemannian metric is a (0,2)-tensor field; its
    components are smooth functions of position on the manifold that
    transform according to the tensor transformation law. The tensor
    transformation is critical in ensuring that lengths and angles are
    consistently defined regardless of the coordinate system chosen. The
    components are scalar-valued functions that must vary smoothly. This
    collection of inner products, along with the smoothness requirement
    and tensorial transformation property of the components, define the
    Riemannian metric, which is a (0,2) tensor.</p>
    <h1 id="arc-length-parameterization">Arc Length
    Parameterization</h1>
    <p><strong>Let <span class="math inline">\(\gamma(t): I \to
    R\)</span> be a curve in <span class="math inline">\(E^n\)</span>.
    How is the length of this curve defined? Further, how can this curve
    be reparameterized in terms of arc length?</strong></p>
    <p><strong>Length of a Curve in <span
    class="math inline">\(\mathbb{E}^n\)</span></strong></p>
    <p>The length <span class="math inline">\(L\)</span> of a smooth
    curve <span class="math inline">\(\gamma: I \to
    \mathbb{E}^n\)</span>, where <span class="math inline">\(I = [a,
    b]\)</span> is a closed interval in <span
    class="math inline">\(\mathbb{R}\)</span>, is defined using the
    Riemannian metric of <span
    class="math inline">\(\mathbb{E}^n\)</span> (the standard Euclidean
    metric). The length is given by the integral of the magnitude of the
    velocity vector:</p>
    <p><span class="math inline">\(L = \int_a^b ||\gamma&#39;(t)|| \,
    dt\)</span></p>
    <p>where <span class="math inline">\(\gamma&#39;(t) =
    \frac{d\gamma}{dt}\)</span> is the velocity vector (tangent vector
    to the curve at <span class="math inline">\(\gamma(t)\)</span>), and
    <span class="math inline">\(||\cdot||\)</span> denotes the Euclidean
    norm (magnitude) of the vector in <span
    class="math inline">\(\mathbb{R}^n\)</span>:</p>
    <p><span class="math inline">\(||\gamma&#39;(t)|| =
    \sqrt{\sum_{i=1}^n \left( \frac{d\gamma^i}{dt}(t)
    \right)^2}\)</span></p>
    <p>if <span class="math inline">\(\gamma(t) = (\gamma^1(t), \dots,
    \gamma^n(t))\)</span> are the coordinate components of <span
    class="math inline">\(\gamma(t)\)</span> in <span
    class="math inline">\(\mathbb{R}^n\)</span>.</p>
    <p><strong>Reparameterization by Arc Length</strong></p>
    <p>To reparameterize <span class="math inline">\(\gamma(t)\)</span>
    by arc length <span class="math inline">\(s\)</span>, we first
    compute the arc length function:</p>
    <p><span class="math inline">\(s(t) = \int_a^t ||\gamma&#39;(u)|| \,
    du\)</span></p>
    <p>This gives the arc length from <span
    class="math inline">\(\gamma(a)\)</span> to <span
    class="math inline">\(\gamma(t)\)</span>.</p>
    <ol type="1">
    <li><p><strong>Derivative of Arc Length:</strong> The derivative of
    the arc length function with respect to <span
    class="math inline">\(t\)</span> is:</p>
    <p><span class="math inline">\(\frac{ds}{dt} =
    ||\gamma&#39;(t)||\)</span> (This follows from the Fundamental
    Theorem of Calculus). This is the speed at time <span
    class="math inline">\(t\)</span>.</p></li>
    </ol>
    <p>This is a strictly monotonically increasing function if the
    velocity of <span class="math inline">\(\gamma\)</span> is non-zero
    for all <span class="math inline">\(t\)</span>, so it is invertible.
    The inverse function is <span
    class="math inline">\(t(s)\)</span>.</p>
    <p>The reparameterization of <span
    class="math inline">\(\gamma\)</span> by arc length is given by:</p>
    <p><span class="math inline">\(\tilde{\gamma}(s) =
    \gamma(t(s))\)</span></p>
    <p>where <span class="math inline">\(t(s)\)</span> is the inverse of
    <span class="math inline">\(s(t)\)</span>. <span
    class="math inline">\(\tilde{\gamma}(s)\)</span> traces out the same
    curve, but the parameter is now the arc length <span
    class="math inline">\(s\)</span>.</p>
    <ol start="2" type="1">
    <li><p><strong>Derivative of Reparameterized Curve:</strong> To show
    that the velocity of the reparameterized curve has magnitude 1, we
    use the chain rule:</p>
    <p><span class="math inline">\(\tilde{\gamma}&#39;(s) =
    \frac{d\gamma}{dt}(t(s)) \frac{dt}{ds}(s)\)</span></p>
    <p>Since <span class="math inline">\(\frac{ds}{dt} =
    ||\gamma&#39;(t)||\)</span>, we have <span
    class="math inline">\(\frac{dt}{ds} =
    \frac{1}{||\gamma&#39;(t(s))||}\)</span>. Therefore:</p>
    <p><span class="math inline">\(\tilde{\gamma}&#39;(s) =
    \frac{\gamma&#39;(t(s))}{||\gamma&#39;(t(s))||}\)</span></p>
    <p>Thus:</p>
    <p><span class="math inline">\(||\tilde{\gamma}&#39;(s)|| =
    \frac{||\gamma&#39;(t(s))||}{||\gamma&#39;(t(s))||} =
    1\)</span></p></li>
    </ol>
    <p>The reparameterized curve <span
    class="math inline">\(\tilde{\gamma}(s)\)</span> has unit speed
    (<span class="math inline">\(||\tilde{\gamma}&#39;(s)|| =
    1\)</span>), making <span class="math inline">\(s\)</span> the arc
    length parameter. This process requires the velocity of the curve to
    be non-zero.</p>
    <h1 id="curvature-of-a-curve">Curvature of a curve</h1>
    <p><strong>Let <span class="math inline">\(c: I \to E^n\)</span> be
    a curve parameterized by arc length. Then we have <span
    class="math inline">\(\Vert c’(s)\Vert = 1\)</span>. Let <span
    class="math inline">\(T(s) = c’(s)\)</span> is vector valued
    function. <span class="math inline">\(dT/ds\)</span> is a vector
    valued function whose magnitude must be a measure of how much the
    curve bends, since if <span class="math inline">\(c(s)\)</span> were
    straight, <span class="math inline">\(\Vert dT/ds\Vert = 0\)</span>.
    Is this correct?</strong></p>
    <p>Yes, you’re absolutely correct. For a curve <span
    class="math inline">\(c: I \to \mathbb{E}^n\)</span> parameterized
    by arc length <span class="math inline">\(s\)</span>, the
    vector-valued function <span class="math inline">\(T(s) =
    c&#39;(s)\)</span> is the unit tangent vector to the curve at <span
    class="math inline">\(c(s)\)</span>. The derivative <span
    class="math inline">\(\frac{dT}{ds}(s)\)</span> measures the rate of
    change of the tangent vector with respect to arc length, which is
    directly related to the curvature of the curve. Here’s why:</p>
    <ol type="1">
    <li><p><strong>Unit Tangent Vector:</strong> Since <span
    class="math inline">\(c(s)\)</span> is parameterized by arc length,
    <span class="math inline">\(||T(s)|| = ||c&#39;(s)|| = 1\)</span>
    for all <span class="math inline">\(s\)</span>. This means that
    <span class="math inline">\(T(s)\)</span> is a unit vector.</p></li>
    <li><p><strong>Derivative Measures Bending:</strong> The derivative
    <span class="math inline">\(\frac{dT}{ds}(s)\)</span> represents the
    rate at which the unit tangent vector changes as we move along the
    curve. If the curve were a straight line, the tangent vector would
    be constant, and <span
    class="math inline">\(\frac{dT}{ds}(s)\)</span> would be the zero
    vector.</p></li>
    <li><p><strong>Curvature:</strong> The magnitude of <span
    class="math inline">\(\frac{dT}{ds}(s)\)</span> is, in fact, the
    curvature <span class="math inline">\(\kappa(s)\)</span> of the
    curve at <span class="math inline">\(c(s)\)</span>:</p>
    <p><span class="math inline">\(\kappa(s) = \left\| \frac{dT}{ds}(s)
    \right\|\)</span></p>
    <p>The curvature quantifies how much the curve bends at each point.
    A higher curvature means a sharper bend. A straight line has zero
    curvature.</p></li>
    <li><p><strong>Osculating Plane:</strong> The vector <span
    class="math inline">\(\frac{dT}{ds}(s)\)</span> is orthogonal to
    <span class="math inline">\(T(s)\)</span> because <span
    class="math inline">\(T(s)\)</span> has unit length and therefore
    the derivative is orthogonal to <span
    class="math inline">\(T(s)\)</span>. The vector <span
    class="math inline">\(\frac{dT}{ds}(s)\)</span> lies in the
    <em>osculating plane</em>, which is the plane that best approximates
    the curve locally. The magnitude represents the rate of change in
    the direction of the tangent vector.</p></li>
    </ol>
    <p>In summary, your intuition is spot on. The magnitude of <span
    class="math inline">\(\frac{dT}{ds}(s)\)</span> gives the curvature
    of the curve at <span class="math inline">\(c(s)\)</span>, providing
    a quantitative measure of how much the curve is bending at that
    point. The vector <span
    class="math inline">\(\frac{dT}{ds}(s)\)</span> lies in the
    osculating plane and is orthogonal to the tangent vector, pointing
    in the direction of the curvature. It measures how much the tangent
    vector is turning per unit arc length. The norm is a measure of how
    fast the tangent vector is turning.</p>
    <p><strong>Provide a rigorous explanation of why <span
    class="math inline">\(dT/ds\)</span> is orthogonal to <span
    class="math inline">\(T(s)\)</span>.</strong></p>
    <p>The rigorous explanation of why <span
    class="math inline">\(\frac{dT}{ds}\)</span> is orthogonal to <span
    class="math inline">\(T(s)\)</span> for a curve parameterized by arc
    length relies on the fact that <span
    class="math inline">\(T(s)\)</span> is a unit vector for all <span
    class="math inline">\(s\)</span>.</p>
    <p><strong>1. Unit Tangent Vector:</strong></p>
    <p>Since the curve <span class="math inline">\(c(s)\)</span> is
    parameterized by arc length, the tangent vector <span
    class="math inline">\(T(s) = c&#39;(s)\)</span> has unit length for
    all <span class="math inline">\(s\)</span>:</p>
    <p><span class="math inline">\(||T(s)|| = 1\)</span> for all <span
    class="math inline">\(s\)</span></p>
    <p>This means that the dot product of <span
    class="math inline">\(T(s)\)</span> with itself is always 1:</p>
    <p><span class="math inline">\(T(s) \cdot T(s) = ||T(s)||^2 =
    1\)</span></p>
    <p><strong>2. Differentiating with Respect to <span
    class="math inline">\(s\)</span>:</strong></p>
    <p>Now, differentiate both sides of the equation <span
    class="math inline">\(T(s) \cdot T(s) = 1\)</span> with respect to
    <span class="math inline">\(s\)</span>. Using the product rule for
    dot products, we get:</p>
    <p><span class="math inline">\(\frac{d}{ds}(T(s) \cdot T(s)) =
    \frac{dT}{ds}(s) \cdot T(s) + T(s) \cdot \frac{dT}{ds}(s) = 2 \left(
    T(s) \cdot \frac{dT}{ds}(s) \right) = 0\)</span></p>
    <p>The derivative of the constant 1 is 0.</p>
    <p><strong>3. Orthogonality:</strong></p>
    <p>Since <span class="math inline">\(2 \left( T(s) \cdot
    \frac{dT}{ds}(s) \right) = 0\)</span>, we have:</p>
    <p><span class="math inline">\(T(s) \cdot \frac{dT}{ds}(s) =
    0\)</span></p>
    <p>This equation shows that the dot product of <span
    class="math inline">\(T(s)\)</span> and <span
    class="math inline">\(\frac{dT}{ds}(s)\)</span> is zero. By the
    definition of the dot product, this means that the vectors <span
    class="math inline">\(T(s)\)</span> and <span
    class="math inline">\(\frac{dT}{ds}(s)\)</span> are orthogonal
    (perpendicular) to each other for all <span
    class="math inline">\(s\)</span>.</p>
    <p><strong>In Summary:</strong></p>
    <p>The orthogonality of <span class="math inline">\(T(s)\)</span>
    and <span class="math inline">\(\frac{dT}{ds}(s)\)</span> is a
    direct consequence of the fact that <span
    class="math inline">\(T(s)\)</span> has constant unit length.
    Differentiating the equation <span class="math inline">\(T(s) \cdot
    T(s) = 1\)</span> with respect to <span
    class="math inline">\(s\)</span> and applying the product rule
    immediately leads to the orthogonality condition. This is a
    fundamental result in the differential geometry of curves. The fact
    that the tangent vector has a constant length is crucial in showing
    orthogonality between the tangent and its derivative. If the length
    were not constant, then the vectors would not be orthogonal.</p>
    <p><strong>Let <span class="math inline">\(\gamma(t): I \to
    E^n\)</span> be a regular curve. Let <span
    class="math inline">\(\{E_1(t), \cdots, E_n(t) \}\)</span> be a list
    of smooth, orthonormal vector fields in <span
    class="math inline">\(E^n\)</span> such that $E_1(t) = (t)/(t) $.
    This looks like special coordinate system which is moving along the
    curve and at a given <span class="math inline">\(t\)</span>, we can
    identify them with the unit vectors of the tangent space. How is
    this related to the Frenet Frame</strong></p>
    <p>You’ve described a moving frame along the curve <span
    class="math inline">\(\gamma(t)\)</span>, and it’s closely related
    to the Frenet frame, but it’s not quite the same thing. Let’s
    clarify the relationship:</p>
    <p><strong>Your Moving Frame:</strong></p>
    <p>You’ve defined a set of orthonormal vector fields <span
    class="math inline">\(\{E_1(t), \dots, E_n(t)\}\)</span> along the
    curve <span class="math inline">\(\gamma(t)\)</span> such that <span
    class="math inline">\(E_1(t)\)</span> is the unit tangent vector.
    This is a moving orthonormal frame in <span
    class="math inline">\(\mathbb{E}^n\)</span> that’s adapted to the
    curve, meaning one of the frame vectors is always tangent to the
    curve.</p>
    <p><strong>Frenet Frame:</strong></p>
    <p>The Frenet frame is a <em>specific</em> moving orthonormal frame
    that is defined for a curve in <span
    class="math inline">\(\mathbb{E}^n\)</span>. It’s constructed using
    the derivatives of the curve’s tangent vector.</p>
    <ul>
    <li><p><strong>Unit Tangent Vector:</strong> <span
    class="math inline">\(T(s) = c&#39;(s)\)</span> is the unit tangent
    vector (where <span class="math inline">\(s\)</span> is arc
    length).</p></li>
    <li><p><strong>Principal Normal Vector:</strong> <span
    class="math inline">\(N(s) = \frac{T&#39;(s)}{|T&#39;(s)|}\)</span>
    is the unit principal normal vector, pointing in the direction of
    the curvature. This assumes <span
    class="math inline">\(T&#39;(s)\)</span> is non-zero.</p></li>
    <li><p><strong>Binormal Vector (if <span
    class="math inline">\(n=3\)</span>):</strong> <span
    class="math inline">\(B(s) = T(s) \times N(s)\)</span> is the
    binormal vector. This is defined for curves in <span
    class="math inline">\(E^3\)</span>.</p></li>
    </ul>
    <p>The Frenet frame is <span class="math inline">\(\{T(s), N(s),
    B(s)\}\)</span> for <span class="math inline">\(n=3\)</span> which
    consists of the tangent, principal normal, and binormal vectors at
    each point. It can be extended to higher dimensions. The Frenet
    frame vectors are orthonormal. The Frenet frame vectors are defined
    in terms of derivatives of the curve.</p>
    <p><strong>Relationship:</strong></p>
    <p>Your moving frame is a <em>generalization</em> of the Frenet
    frame. The Frenet frame is a specific orthonormal frame that is
    uniquely defined (up to orientation for <span
    class="math inline">\(N(s)\)</span> and <span
    class="math inline">\(B(s)\)</span>) for a curve. Your frame is an
    orthonormal frame but it is not unique. It only requires that <span
    class="math inline">\(E_1(t)\)</span> is the unit tangent vector,
    but the other vectors <span class="math inline">\(E_i(t)\)</span>
    for <span class="math inline">\(i&gt;1\)</span> can be chosen
    freely, as long as they form an orthonormal basis.</p>
    <ul>
    <li>Your frame includes the tangent vector but does not explicitly
    include the other Frenet vectors (principal normal, binormal, etc.)
    which are constructed from the derivatives of the tangent vector.
    The other vectors are chosen arbitrarily, subject to the
    orthonormality condition.</li>
    <li>The Frenet frame is particularly useful because it provides a
    natural frame that directly reflects the curve’s geometric
    properties (curvature, torsion).</li>
    <li>Your moving frame is a far more general frame which can be
    chosen in a much wider range of ways. It is not unique, but it can
    be chosen in such a way as to simplify certain calculations.</li>
    </ul>
    <p>In short, the Frenet frame is a specific example of a moving
    orthonormal frame adapted to a curve, while your construction
    describes a broader class of such frames. The Frenet frame uses only
    derivatives of the curve to define the vectors, so it is unique,
    while your frame has a much larger degree of freedom.</p>
    <p>Using Frenet frames or, more generally, moving orthonormal frames
    serves several crucial purposes in differential geometry and its
    applications:</p>
    <ol type="1">
    <li><p><strong>Simplifying Calculations:</strong> Moving frames
    significantly simplify calculations involving curves and surfaces.
    By choosing a frame that’s adapted to the geometry of the curve or
    surface, we can often reduce the complexity of expressions and make
    calculations more manageable. This is particularly useful for
    computing curvature, torsion, and other geometric
    quantities.</p></li>
    <li><p><strong>Analyzing Curvature and Torsion:</strong> The Frenet
    frame is specifically designed to analyze the curvature and torsion
    of a curve. The principal normal vector points in the direction of
    the curve’s curvature, and the binormal vector helps to describe the
    curve’s twisting in three dimensions. The Frenet frame makes these
    calculations simpler.</p></li>
    <li><p><strong>Parallel Transport:</strong> Moving frames are
    essential for understanding parallel transport. Parallel transport
    allows us to compare tangent vectors at different points on a
    manifold. This involves moving vectors along curves while keeping
    them “parallel” in some sense, which requires a connection. The
    choice of the frame affects the result of parallel
    transport.</p></li>
    <li><p><strong>Studying Surfaces:</strong> Moving frames are also
    used extensively in the study of surfaces. By choosing a frame
    that’s adapted to the surface’s geometry (e.g., one vector tangent
    to a curve on the surface and others normal to the surface), we can
    simplify calculations involving surface curvature, geodesics, and
    other surface properties. The choice of frame will often simplify
    the expressions used.</p></li>
    <li><p><strong>Generalizing to Higher Dimensions:</strong> While the
    Frenet frame is primarily defined for curves in <span
    class="math inline">\(\mathbb{R}^3\)</span>, the idea of moving
    frames generalizes to higher dimensions and more complex geometric
    objects. This extension is important for studying higher-dimensional
    manifolds. This is because the Frenet frame only exists for curves
    in <span class="math inline">\(E^3\)</span>.</p></li>
    <li><p><strong>Applications in Physics:</strong> Moving frames have
    important applications in physics, especially in mechanics and
    general relativity. For example, they are used to describe the
    motion of rigid bodies and to construct coordinate systems adapted
    to the geometry of spacetime. They are very useful in the
    formulation of equations of motion.</p></li>
    </ol>
    <p>In essence, moving frames provide a powerful tool for simplifying
    calculations, analyzing geometric properties, and understanding
    fundamental concepts in differential geometry and its applications.
    The choice of frame is crucial, and the Frenet frame is particularly
    useful when studying curves because of its inherent properties
    related to curvature. However, other moving frames are often useful
    in different contexts. The choice of the frame itself often leads to
    simpler calculations and more transparent geometric
    interpretation.</p>
    <p><strong>Give an example of curve <span
    class="math inline">\(c(t)\)</span> in <span
    class="math inline">\(E^3\)</span>. Calculate the arc length <span
    class="math inline">\(s(t)\)</span>. Calculate the arc length
    parameterization of the curve.</strong></p>
    <p>Let’s consider a helix in <span
    class="math inline">\(\mathbb{E}^3\)</span> as an example. The helix
    is a curve that spirals around a cylinder.</p>
    <p><strong>1. Parameterization of the Helix:</strong></p>
    <p>A common parameterization of a helix is:</p>
    <p><span class="math inline">\(c(t) = (a \cos(t), a \sin(t),
    bt)\)</span>, where <span class="math inline">\(a &gt; 0\)</span>
    and <span class="math inline">\(b &gt; 0\)</span> are constants.</p>
    <p>Here, <span class="math inline">\(a\)</span> is the radius of the
    cylinder around which the helix spirals, and <span
    class="math inline">\(b\)</span> determines the vertical “pitch” of
    the helix. The parameter <span class="math inline">\(t\)</span> is
    an arbitrary parameter.</p>
    <p><strong>2. Calculation of Arc Length <span
    class="math inline">\(s(t)\)</span>:</strong></p>
    <p>To find the arc length, we first compute the velocity vector:</p>
    <p><span class="math inline">\(c&#39;(t) = (-a \sin(t), a \cos(t),
    b)\)</span></p>
    <p>The magnitude of the velocity vector is:</p>
    <p><span class="math inline">\(||c&#39;(t)|| = \sqrt{(-a \sin(t))^2
    + (a \cos(t))^2 + b^2} = \sqrt{a^2 + b^2}\)</span></p>
    <p>The arc length function <span class="math inline">\(s(t)\)</span>
    from <span class="math inline">\(t=0\)</span> is given by:</p>
    <p><span class="math inline">\(s(t) = \int_0^t ||c&#39;(u)|| \, du =
    \int_0^t \sqrt{a^2 + b^2} \, du = t \sqrt{a^2 + b^2}\)</span></p>
    <p><strong>3. Arc Length Parameterization:</strong></p>
    <p>To obtain the arc length parameterization, we solve for <span
    class="math inline">\(t\)</span> in terms of <span
    class="math inline">\(s\)</span>:</p>
    <p><span class="math inline">\(t(s) = \frac{s}{\sqrt{a^2 +
    b^2}}\)</span></p>
    <p>Substituting this into the original parameterization, we get the
    arc length parameterization:</p>
    <p><span class="math inline">\(\tilde{c}(s) = \left( a \cos\left(
    \frac{s}{\sqrt{a^2 + b^2}} \right), a \sin\left( \frac{s}{\sqrt{a^2
    + b^2}} \right), \frac{bs}{\sqrt{a^2 + b^2}} \right)\)</span></p>
    <p>This parameterization has the property that <span
    class="math inline">\(||\tilde{c}&#39;(s)|| = 1\)</span> for all
    <span class="math inline">\(s\)</span>. This ensures that <span
    class="math inline">\(s\)</span> truly represents the arc length.
    The speed of this parameterization is 1.</p>
    <p>In summary, for the helix <span class="math inline">\(c(t) = (a
    \cos(t), a \sin(t), bt)\)</span>, the arc length is <span
    class="math inline">\(s(t) = t\sqrt{a^2 + b^2}\)</span>, and the arc
    length parameterization is given by <span
    class="math inline">\(\tilde{c}(s)\)</span> as shown above. The arc
    length parameterization provides a more natural and often more
    useful parameterization of the curve since the parameter is now the
    arc length itself. The speed of this parameterization is always 1.
    This makes it simpler to calculate quantities such as curvature and
    torsion.</p>
    <p>Let’s calculate the Frenet frame (tangent, normal, and binormal
    vectors) for the arc length parameterization of the helix we derived
    earlier:</p>
    <p><span class="math inline">\(\tilde{c}(s) = \left( a \cos\left(
    \frac{s}{\sqrt{a^2 + b^2}} \right), a \sin\left( \frac{s}{\sqrt{a^2
    + b^2}} \right), \frac{bs}{\sqrt{a^2 + b^2}} \right)\)</span></p>
    <p><strong>1. Unit Tangent Vector <span
    class="math inline">\(T(s)\)</span>:</strong></p>
    <p>The tangent vector is the derivative with respect to arc
    length:</p>
    <p><span class="math inline">\(\tilde{c}&#39;(s) = T(s) = \left(
    -\frac{a}{\sqrt{a^2 + b^2}} \sin\left( \frac{s}{\sqrt{a^2 + b^2}}
    \right), \frac{a}{\sqrt{a^2 + b^2}} \cos\left( \frac{s}{\sqrt{a^2 +
    b^2}} \right), \frac{b}{\sqrt{a^2 + b^2}} \right)\)</span></p>
    <p>Since the parameterization is by arc length, this is already a
    unit vector: <span class="math inline">\(||T(s)|| = 1\)</span>.</p>
    <p><strong>2. Principal Normal Vector <span
    class="math inline">\(N(s)\)</span>:</strong></p>
    <p>The principal normal vector is given by:</p>
    <p><span class="math inline">\(N(s) =
    \frac{T&#39;(s)}{|T&#39;(s)|}\)</span></p>
    <p>First, we compute the derivative of the tangent vector:</p>
    <p><span class="math inline">\(T&#39;(s) = \left( -\frac{a}{a^2 +
    b^2} \cos\left( \frac{s}{\sqrt{a^2 + b^2}} \right), -\frac{a}{a^2 +
    b^2} \sin\left( \frac{s}{\sqrt{a^2 + b^2}} \right), 0
    \right)\)</span></p>
    <p>The magnitude of <span class="math inline">\(T&#39;(s)\)</span>
    is:</p>
    <p><span class="math inline">\(||T&#39;(s)|| = \frac{a}{a^2 +
    b^2}\)</span></p>
    <p>Therefore, the principal normal vector is:</p>
    <p><span class="math inline">\(N(s) = \left( -\cos\left(
    \frac{s}{\sqrt{a^2 + b^2}} \right), -\sin\left( \frac{s}{\sqrt{a^2 +
    b^2}} \right), 0 \right)\)</span></p>
    <p><strong>3. Binormal Vector <span
    class="math inline">\(B(s)\)</span>:</strong></p>
    <p>The binormal vector is the cross product of the tangent and
    normal vectors:</p>
    <p><span class="math inline">\(B(s) = T(s) \times N(s) = \left(
    \frac{b}{\sqrt{a^2 + b^2}} \sin\left( \frac{s}{\sqrt{a^2 + b^2}}
    \right), -\frac{b}{\sqrt{a^2 + b^2}} \cos\left( \frac{s}{\sqrt{a^2 +
    b^2}} \right), \frac{a}{\sqrt{a^2 + b^2}} \right)\)</span></p>
    <p>In summary, for this helix parameterized by arc length, we’ve
    calculated the unit tangent, principal normal, and binormal vectors.
    Notice that the binormal vector is constant along the helix, meaning
    that the helix does not twist in space. The principal normal vector
    always points toward the central axis of the helix. The tangent
    vector is always tangent to the helix.</p>
    <p><strong>Is there a way to generalize the idea of Frenet frame to
    higher dimensions?</strong></p>
    <p>Yes, the Frenet frame can be generalized to curves in <span
    class="math inline">\(\mathbb{R}^n\)</span> for <span
    class="math inline">\(n &gt; 3\)</span>. However, it becomes more
    complex because we need more than just the tangent, normal, and
    binormal vectors.</p>
    <p><strong>Generalization:</strong></p>
    <p>The generalization uses the concept of higher-order derivatives
    of the curve. Assuming that the curve is parameterized by arc length
    <span class="math inline">\(s\)</span>, the generalization is as
    follows:</p>
    <ol type="1">
    <li><p><strong>Unit Tangent Vector:</strong> <span
    class="math inline">\(T_1(s) = c&#39;(s)\)</span>, where <span
    class="math inline">\(||T_1(s)|| = 1\)</span>.</p></li>
    <li><p><strong>Higher-Order Vectors:</strong> We recursively define
    the higher-order vectors by:</p>
    <p><span class="math inline">\(T_{k+1}(s) = \frac{T&#39;_k(s) -
    \langle T&#39;_k(s), T_k(s) \rangle T_k(s)}{||T&#39;_k(s) - \langle
    T&#39;_k(s), T_k(s) \rangle T_k(s)||}\)</span> for <span
    class="math inline">\(k=1, \dots, n-1\)</span>.</p>
    <p>This formula ensures that each vector <span
    class="math inline">\(T_k(s)\)</span> is a unit vector and is
    orthogonal to all the previous vectors <span
    class="math inline">\(T_1(s), \dots, T_{k-1}(s)\)</span>. If the
    denominator is zero, then we can’t define the next vector. There
    will be fewer than n Frenet vectors in this case.</p></li>
    <li><p><strong>Frenet Frame:</strong> The Frenet frame at <span
    class="math inline">\(c(s)\)</span> consists of the orthonormal set
    of vectors <span class="math inline">\(\{T_1(s), \dots,
    T_m(s)\}\)</span>, where <span class="math inline">\(m \le
    n\)</span> is the number of linearly independent vectors that can be
    constructed in this way. The number of linearly independent vectors
    is related to the order of contact between the curve and its
    osculating hyperplanes.</p></li>
    </ol>
    <p><strong>Curvature:</strong></p>
    <p>The curvature functions <span
    class="math inline">\(\kappa_k(s)\)</span> are defined as:</p>
    <p><span class="math inline">\(\kappa_k(s) = ||T&#39;_k(s) - \langle
    T&#39;_k(s), T_k(s) \rangle T_k(s)||\)</span> for <span
    class="math inline">\(k=1, \dots, n-1\)</span>.</p>
    <p>Each curvature measures how much the curve is “bending” in a
    higher-dimensional sense.</p>
    <p><strong>Limitations:</strong></p>
    <ul>
    <li>The process of constructing the Frenet frame only works if the
    vectors <span class="math inline">\(T_k\)</span> are all linearly
    independent.</li>
    <li>If the curvature is zero for some <span
    class="math inline">\(k\)</span>, the higher order vectors cannot be
    uniquely defined.</li>
    <li>The Frenet frame may only have fewer than <span
    class="math inline">\(n\)</span> vectors.</li>
    </ul>
    <p><strong>In Summary:</strong></p>
    <p>The Frenet frame generalizes to higher dimensions by recursively
    constructing unit tangent vectors that are orthogonal to those
    previously constructed. The process is not always possible, and the
    number of vectors in the frame is determined by the curve’s
    geometry. This generalization is useful for analyzing curvature in
    higher dimensions, although it is not unique in all cases. It is
    unique up to orientation.</p>
    <h1 id="covariant-derivative-1">Covariant Derivative 1</h1>
    <p>On the manifold <span class="math inline">\(\mathbb{E}^n\)</span>
    (Euclidean <span class="math inline">\(n\)</span>-space), the
    covariant derivative of a vector field <span
    class="math inline">\(Y\)</span> with respect to another vector
    field <span class="math inline">\(X\)</span> is simply the
    directional derivative of <span class="math inline">\(Y\)</span>
    along <span class="math inline">\(X\)</span>. This is because <span
    class="math inline">\(\mathbb{E}^n\)</span> has a natural, flat
    connection, meaning there’s a preferred way to compare tangent
    vectors at different points. The covariant derivative is a vector
    field.</p>
    <p><strong>1. Vector Fields in Local Coordinates:</strong></p>
    <p>Let’s work in the standard Cartesian coordinate system of <span
    class="math inline">\(\mathbb{E}^n\)</span>. The vector fields <span
    class="math inline">\(X\)</span> and <span
    class="math inline">\(Y\)</span> can be expressed as:</p>
    <p><span class="math inline">\(X = \sum_{i=1}^n X^i
    \frac{\partial}{\partial x^i}\)</span> <span class="math inline">\(Y
    = \sum_{j=1}^n Y^j \frac{\partial}{\partial x^j}\)</span></p>
    <p>where <span class="math inline">\(X^i(x)\)</span> and <span
    class="math inline">\(Y^j(x)\)</span> are the components of <span
    class="math inline">\(X\)</span> and <span
    class="math inline">\(Y\)</span> at the point <span
    class="math inline">\(x = (x^1, \dots, x^n)\)</span>, which are
    smooth functions of the position.</p>
    <p><strong>2. Covariant Derivative as Directional
    Derivative:</strong></p>
    <p>The covariant derivative of <span
    class="math inline">\(Y\)</span> with respect to <span
    class="math inline">\(X\)</span>, denoted <span
    class="math inline">\(\nabla_X Y\)</span>, is given by:</p>
    <p><span class="math inline">\((\nabla_X Y)^i = \sum_{j=1}^n X^j
    \frac{\partial Y^i}{\partial x^j}\)</span></p>
    <p>This is precisely the directional derivative of the <span
    class="math inline">\(i\)</span>-th component of <span
    class="math inline">\(Y\)</span> along the vector field <span
    class="math inline">\(X\)</span>. It shows how the <span
    class="math inline">\(i\)</span>-th component of <span
    class="math inline">\(Y\)</span> changes along the direction of
    <span class="math inline">\(X\)</span>. This formula holds because
    the connection is flat and the Christoffel symbols are all zero in
    the standard coordinate system.</p>
    <p><strong>3. Geometric Interpretation:</strong></p>
    <p>Geometrically, <span class="math inline">\((\nabla_X
    Y)_p\)</span> represents the rate of change of the vector field
    <span class="math inline">\(Y\)</span> at a point <span
    class="math inline">\(p\)</span> as we move along the vector field
    <span class="math inline">\(X\)</span> at that point. Since <span
    class="math inline">\(\mathbb{E}^n\)</span> is flat, this
    directional derivative is independent of the path taken to move from
    one point to the other. On curved manifolds, this is not the case.
    The directional derivative would not be path-independent. In the
    flat case of <span class="math inline">\(\mathbb{E}^n\)</span>, we
    can obtain the covariant derivative by using the partial
    derivatives. We can also obtain the covariant derivative by using
    the Lie bracket. However, only in the flat case are they equal.</p>
    <p><strong>4. Relationship to the Lie Bracket:</strong></p>
    <p>In the case of <span class="math inline">\(\mathbb{E}^n\)</span>
    (and in general for flat manifolds):</p>
    <p><span class="math inline">\(\nabla_X Y = \mathcal{L}_X Y = [X,
    Y]\)</span></p>
    <p>where <span class="math inline">\(\mathcal{L}_X Y\)</span> is the
    Lie derivative of <span class="math inline">\(Y\)</span> with
    respect to <span class="math inline">\(X\)</span> (which is defined
    by its action on smooth functions: <span
    class="math inline">\([X,Y](f) = X(Y(f)) - Y(X(f))\)</span> ), and
    <span class="math inline">\([X,Y]\)</span> is the Lie bracket. The
    Lie bracket is a measure of the non-commutativity of the flows
    associated with <span class="math inline">\(X\)</span> and <span
    class="math inline">\(Y\)</span>. The Lie bracket measures the
    failure of the flows to commute. This equality does not hold on
    general curved manifolds.</p>
    <p>In summary, on <span class="math inline">\(\mathbb{E}^n\)</span>,
    the covariant derivative of <span class="math inline">\(Y\)</span>
    with respect to <span class="math inline">\(X\)</span> is simply the
    directional derivative of <span class="math inline">\(Y\)</span>
    along <span class="math inline">\(X\)</span>. This is because <span
    class="math inline">\(\mathbb{E}^n\)</span> is flat, and the
    connection is the standard flat connection. This also happens to be
    equal to the Lie derivative and the Lie bracket. These three are not
    equal on general curved manifolds.</p>
    <h1 id="covariant-derivative-2">Covariant Derivative 2</h1>
    <p><strong>Consider the manifold <span
    class="math inline">\(E^n\)</span>. Let <span
    class="math inline">\(Y\)</span> be a vector field defined on <span
    class="math inline">\(E^n\)</span>. Consider a curve <span
    class="math inline">\(c(t): I \to E^n\)</span>. Let <span
    class="math inline">\(X\)</span> be a vector field along <span
    class="math inline">\(c(t)\)</span>; it assigns a specific tangent
    vector <span class="math inline">\(X_p = v_p = dc(t)/dt
    |_p\)</span>. We are interested in how the vector field <span
    class="math inline">\(Y\)</span> changes as we move along the curve
    <span class="math inline">\(c(t)\)</span> defined by <span
    class="math inline">\(X\)</span>. Does this concept make sense and
    if so, formalize this with details.</strong></p>
    <p>Yes, this concept makes perfect sense. It’s the core idea behind
    the <strong>covariant derivative</strong> of a vector field along a
    curve. Here’s a formalization:</p>
    <ol type="1">
    <li><p><strong>Vector Field along a Curve:</strong> As you stated, a
    vector field <span class="math inline">\(X\)</span> along a curve
    <span class="math inline">\(c(t)\)</span> in <span
    class="math inline">\(E^n\)</span> assigns a tangent vector <span
    class="math inline">\(X_{c(t)} \in T_{c(t)}E^n\)</span> to each
    point <span class="math inline">\(c(t)\)</span> on the curve.
    Importantly, <span class="math inline">\(X\)</span> doesn’t need to
    be defined on all of <span class="math inline">\(E^n\)</span>, only
    along the image of <span class="math inline">\(c\)</span>. The
    velocity vector field of the curve, <span
    class="math inline">\(\frac{dc}{dt}\)</span>, is a specific example
    of a vector field along <span
    class="math inline">\(c\)</span>.</p></li>
    <li><p><strong>The Vector Field <em>Y</em>:</strong> <span
    class="math inline">\(Y\)</span> is a vector field defined on an
    open subset of <span class="math inline">\(E^n\)</span> that
    contains the image of <span class="math inline">\(c(t)\)</span>. For
    each point <span class="math inline">\(p\)</span> in this subset,
    <span class="math inline">\(Y\)</span> assigns a tangent vector
    <span class="math inline">\(Y_p \in T_pE^n\)</span>.</p></li>
    <li><p><strong>Change of <em>Y</em> along <em>c</em>:</strong> We
    want to understand how <span class="math inline">\(Y\)</span>
    changes as we move along <span class="math inline">\(c(t)\)</span>.
    Since <span class="math inline">\(X = \frac{dc}{dt}\)</span> is the
    velocity vector field of the curve, it tells us how we are moving.
    The change of <span class="math inline">\(Y\)</span> along <span
    class="math inline">\(c\)</span> is given by the <strong>covariant
    derivative</strong> of <span class="math inline">\(Y\)</span> along
    <span class="math inline">\(X\)</span>, denoted by <span
    class="math inline">\(\nabla_X Y\)</span>.</p></li>
    <li><p><strong>Covariant Derivative in <span
    class="math inline">\(E^n\)</span></strong>: In <span
    class="math inline">\(E^n\)</span>, which has a flat connection, the
    covariant derivative is simply the directional derivative. If we
    express <span class="math inline">\(Y\)</span> in standard Cartesian
    coordinates as <span class="math inline">\(Y = \sum_{i=1}^n Y^i
    \frac{\partial}{\partial x^i}\)</span>, and <span
    class="math inline">\(c(t) = (c^1(t), \dots, c^n(t))\)</span>,
    then:</p>
    <p><span class="math display">\[ \nabla_X Y = \frac{d}{dt} Y(c(t)) =
    \sum_{i=1}^n \frac{d}{dt} (Y^i(c(t))) \frac{\partial}{\partial x^i}
    =  \sum_{i,j=1}^n \frac{\partial Y^i}{\partial x^j}
    \frac{dc^j}{dt}  \frac{\partial}{\partial x^i} \]</span></p>
    <p>In other words, we evaluate <span
    class="math inline">\(Y\)</span> along the curve <span
    class="math inline">\(c(t)\)</span> to get <span
    class="math inline">\(Y(c(t))\)</span>, and then we differentiate
    this vector-valued function with respect to <span
    class="math inline">\(t\)</span>.</p></li>
    <li><p><strong>Example:</strong> Let <span class="math inline">\(Y =
    x \frac{\partial}{\partial x} + y \frac{\partial}{\partial
    y}\)</span> in <span class="math inline">\(E^2\)</span>, and let
    <span class="math inline">\(c(t) = (t, t^2)\)</span>. Then <span
    class="math inline">\(X = \frac{dc}{dt} = \frac{\partial}{\partial
    x} + 2t \frac{\partial}{\partial y}\)</span>. We have <span
    class="math inline">\(Y(c(t)) = t\frac{\partial}{\partial x} + t^2
    \frac{\partial}{\partial y}\)</span>. Thus,</p>
    <p><span class="math display">\[ \nabla_X Y =
    \frac{d}{dt}(t\frac{\partial}{\partial x} + t^2
    \frac{\partial}{\partial y}) = \frac{\partial}{\partial x} + 2t
    \frac{\partial}{\partial y} \]</span></p></li>
    </ol>
    <p>In summary, the covariant derivative <span
    class="math inline">\(\nabla_X Y\)</span> precisely formalizes the
    notion of how the vector field <span
    class="math inline">\(Y\)</span> changes along the curve <span
    class="math inline">\(c(t)\)</span> whose velocity vector field is
    <span class="math inline">\(X\)</span>. In <span
    class="math inline">\(E^n\)</span>, the covariant derivative
    simplifies to the ordinary derivative of the vector components of
    <span class="math inline">\(Y(c(t))\)</span>.</p>
    <p><strong>Does this apply if <span class="math inline">\(X\)</span>
    assigns a tangent vector which is not the velocity vector of the
    curve <span class="math inline">\(c(t)\)</span>?</strong></p>
    <p>Yes, the covariant derivative <span
    class="math inline">\(\nabla_X Y\)</span> is still defined even if
    <span class="math inline">\(X\)</span> is a general vector field
    along <span class="math inline">\(c(t)\)</span> and not specifically
    the velocity vector field <span
    class="math inline">\(dc/dt\)</span>. However, the interpretation
    changes slightly.</p>
    <p>When <span class="math inline">\(X = dc/dt\)</span>, <span
    class="math inline">\(\nabla_X Y\)</span> captures the change in
    <span class="math inline">\(Y\)</span> as we move <em>along the
    curve with its inherent parameterization</em>.</p>
    <p>When <span class="math inline">\(X\)</span> is an arbitrary
    vector field along <span class="math inline">\(c\)</span>, <span
    class="math inline">\(\nabla_X Y\)</span> still represents a rate of
    change of <span class="math inline">\(Y\)</span>, but now it’s a
    directional derivative of <span class="math inline">\(Y\)</span> in
    the direction of <span class="math inline">\(X\)</span> at each
    point on <span class="math inline">\(c(t)\)</span>. This direction
    is not necessarily tangent to the curve’s velocity. Think of it like
    measuring the change in <span class="math inline">\(Y\)</span> as
    you move along a path “influenced” by <span
    class="math inline">\(X\)</span> at each point on <span
    class="math inline">\(c\)</span>.</p>
    <p>The formula for <span class="math inline">\(\nabla_X Y\)</span>
    in <span class="math inline">\(E^n\)</span> remains the same:</p>
    <p><span class="math display">\[ \nabla_X Y = \sum_{i,j=1}^n
    \frac{\partial Y^i}{\partial x^j} X^j  \frac{\partial}{\partial x^i}
    \]</span></p>
    <p>where <span class="math inline">\(X = \sum_{j=1}^n X^j
    \frac{\partial}{\partial x^j}\)</span>. Notice that now the <span
    class="math inline">\(X^j\)</span> components are not necessarily
    <span class="math inline">\(dc^j/dt\)</span>, but rather the
    components of the given vector field <span
    class="math inline">\(X\)</span> along <span
    class="math inline">\(c\)</span>.</p>
    <p><strong>Example:</strong></p>
    <p>Let’s use the same <span class="math inline">\(Y\)</span> and
    <span class="math inline">\(c(t)\)</span> as before: <span
    class="math inline">\(Y = x \frac{\partial}{\partial x} + y
    \frac{\partial}{\partial y}\)</span> and <span
    class="math inline">\(c(t) = (t, t^2)\)</span>. But now, let <span
    class="math inline">\(X = 2t \frac{\partial}{\partial x} +
    \frac{\partial}{\partial y}\)</span>. This <span
    class="math inline">\(X\)</span> is still a vector field along <span
    class="math inline">\(c\)</span>, but it’s not <span
    class="math inline">\(dc/dt\)</span>. Then:</p>
    <p><span class="math inline">\(Y(c(t)) = t \frac{\partial}{\partial
    x} + t^2 \frac{\partial}{\partial y}\)</span>, and</p>
    <p><span class="math display">\[ \nabla_X Y = \sum_{i,j=1}^2
    \frac{\partial Y^i}{\partial x^j} X^j \frac{\partial}{\partial x^i}
    = \frac{\partial Y^1}{\partial x} X^1 \frac{\partial}{\partial x}
    +  \frac{\partial Y^2}{\partial y} X^2 \frac{\partial}{\partial y} =
    (1)(2t) \frac{\partial}{\partial x} + (1)(1)
    \frac{\partial}{\partial y} = 2t \frac{\partial}{\partial x} +
    \frac{\partial}{\partial y} \]</span></p>
    <p>So, even though <span class="math inline">\(X\)</span> is not the
    velocity of <span class="math inline">\(c\)</span>, <span
    class="math inline">\(\nabla_X Y\)</span> still gives us a
    meaningful directional derivative of <span
    class="math inline">\(Y\)</span> at each point along <span
    class="math inline">\(c\)</span>. It indicates how <span
    class="math inline">\(Y\)</span> is changing as we move in the
    direction specified by <span class="math inline">\(X\)</span> at
    each point on the curve.</p>
    <h1 id="covariant-derivative-3">Covariant Derivative 3</h1>
    <p>Let’s break down the expression for the covariant derivative in
    <span class="math inline">\(E^n\)</span> in more detail using the
    concept of derivations and directional derivartives:</p>
    <p>We have the vector fields:</p>
    <ul>
    <li><span class="math inline">\(X = \sum_{j=1}^n X^j
    \frac{\partial}{\partial x^j}\)</span></li>
    <li><span class="math inline">\(Y = \sum_{i=1}^n Y^i
    \frac{\partial}{\partial x^i}\)</span></li>
    </ul>
    <p>Our goal is to compute <span class="math inline">\(\nabla_X
    Y\)</span>.</p>
    <ol type="1">
    <li><strong>Definition in <span
    class="math inline">\(\mathbf{E^n}\)</span>:</strong></li>
    </ol>
    <p>As discussed, in <span class="math inline">\(E^n\)</span> with
    the standard flat connection and Cartesian coordinates, we
    <em>define</em> the covariant derivative as:</p>
    <p><span class="math inline">\(\nabla_X Y := \sum_{i=1}^n X(Y^i)
    \frac{\partial}{\partial x^i}\)</span></p>
    <p>This is our starting point, specific to <span
    class="math inline">\(E^n\)</span>.</p>
    <ol start="2" type="1">
    <li><strong><span class="math inline">\(\mathbf{X}\)</span> acting
    on <span class="math inline">\(\mathbf{Y^i}\)</span>:</strong></li>
    </ol>
    <p>The term <span class="math inline">\(X(Y^i)\)</span> represents
    the vector field <span class="math inline">\(X\)</span> acting as a
    derivation on the smooth component function <span
    class="math inline">\(Y^i\)</span>. Recall that <span
    class="math inline">\(X\)</span> acting on a smooth function <span
    class="math inline">\(f\)</span> is given by:</p>
    <p><span class="math inline">\(X(f) = \sum_{j=1}^n X^j
    \frac{\partial f}{\partial x^j}\)</span></p>
    <p>So, replacing <span class="math inline">\(f\)</span> with <span
    class="math inline">\(Y^i\)</span>, we have:</p>
    <p><span class="math inline">\(X(Y^i) = \sum_{j=1}^n X^j
    \frac{\partial Y^i}{\partial x^j}\)</span></p>
    <ol start="3" type="1">
    <li><strong>Substituting back:</strong></li>
    </ol>
    <p>Now, we substitute this expression back into the definition of
    the covariant derivative:</p>
    <p><span class="math inline">\(\nabla_X Y = \sum_{i=1}^n \left(
    \sum_{j=1}^n X^j \frac{\partial Y^i}{\partial x^j} \right)
    \frac{\partial}{\partial x^i}\)</span></p>
    <ol start="4" type="1">
    <li><strong>Combining the sums:</strong></li>
    </ol>
    <p>We can combine the summation symbols:</p>
    <p><span class="math inline">\(\nabla_X Y = \sum_{i=1}^n
    \sum_{j=1}^n X^j \frac{\partial Y^i}{\partial x^j}
    \frac{\partial}{\partial x^i}\)</span></p>
    <p>This can also be written as:</p>
    <p><span class="math inline">\(\nabla_X Y = \sum_{i,j=1}^n X^j
    \frac{\partial Y^i}{\partial x^j} \frac{\partial}{\partial
    x^i}\)</span></p>
    <p>This final expression gives us the covariant derivative of <span
    class="math inline">\(Y\)</span> along <span
    class="math inline">\(X\)</span> in <span
    class="math inline">\(E^n\)</span>. The key takeaway is that in
    <span class="math inline">\(E^n\)</span>, the covariant derivative
    simplifies to the directional derivative of the components of <span
    class="math inline">\(Y\)</span> in the direction of <span
    class="math inline">\(X\)</span>, multiplied by the basis vectors.
    This simplification occurs because the connection is flat, and the
    basis vectors are covariantly constant (<span
    class="math inline">\(\nabla_X (\frac{\partial}{\partial x^i}) =
    0\)</span>). This breakdown should make the expression clearer and
    avoid any circular reasoning.</p>
    <h1 id="covariant-derivative-4">Covariant Derivative 4</h1>
    <p><strong>This is the same as the Lie derivative of <span
    class="math inline">\(Y\)</span> with respect to <span
    class="math inline">\(X\)</span> in coordinate form.
    Correct?</strong></p>
    <p>You are right to notice the similarity! In the specific case of
    <span class="math inline">\(E^n\)</span> with the standard flat
    connection and using Cartesian coordinates, the coordinate
    expressions for the covariant derivative <span
    class="math inline">\(\nabla_X Y\)</span> and the Lie derivative
    <span class="math inline">\(\mathcal{L}_X Y\)</span> are indeed the
    same.</p>
    <p>However, it’s <em>crucially important</em> to understand that
    they are conceptually distinct objects, and this equality of
    coordinate expressions is a special case, not a general rule.</p>
    <p>Here’s why:</p>
    <ul>
    <li><p><strong>Covariant Derivative (<span
    class="math inline">\(\nabla_X Y\)</span>):</strong> The covariant
    derivative measures how a vector field <span
    class="math inline">\(Y\)</span> changes as we move along a curve
    whose tangent vector is given by <span
    class="math inline">\(X\)</span>. It fundamentally depends on a
    <em>connection</em>, which tells us how to compare vectors in
    different tangent spaces. In <span
    class="math inline">\(E^n\)</span>, we are implicitly using the
    trivial flat connection.</p></li>
    <li><p><strong>Lie Derivative (<span
    class="math inline">\(\mathcal{L}_X Y\)</span>):</strong> The Lie
    derivative measures the change in <span
    class="math inline">\(Y\)</span> along the flow generated by <span
    class="math inline">\(X\)</span>. It’s an intrinsic operation that
    doesn’t require a connection. It tells us how <span
    class="math inline">\(Y\)</span> changes when we “drag” it along the
    integral curves of <span class="math inline">\(X\)</span>.</p></li>
    </ul>
    <p><strong>Why the expressions are the same in <span
    class="math inline">\(\mathbf{E^n}\)</span> with Cartesian
    coordinates:</strong></p>
    <p>In Cartesian coordinates on <span
    class="math inline">\(E^n\)</span>, the components of the Lie
    derivative are given by:</p>
    <p><span class="math inline">\((\mathcal{L}_X Y)^i = \sum_{j=1}^n
    \left( X^j \frac{\partial Y^i}{\partial x^j} - Y^j \frac{\partial
    X^i}{\partial x^j} \right)\)</span></p>
    <p>If we compute the covariant derivative using our earlier
    formula:</p>
    <p><span class="math inline">\((\nabla_X Y)^i = \sum_{j=1}^n X^j
    \frac{\partial Y^i}{\partial x^j}\)</span></p>
    <p>The difference between the two is:</p>
    <p><span class="math inline">\((\mathcal{L}_X Y)^i - (\nabla_X Y)^i
    = - \sum_{j=1}^n Y^j \frac{\partial X^i}{\partial x^j} = - (\nabla_Y
    X)^i\)</span></p>
    <p>In other words:</p>
    <p><span class="math inline">\(\mathcal{L}_X Y = \nabla_X Y -
    \nabla_Y X\)</span></p>
    <p>This relationship is true in general (for a torsion-free
    connection). In <span class="math inline">\(E^n\)</span>, with the
    standard coordinates and flat connection, if we choose <span
    class="math inline">\(X\)</span> such that <span
    class="math inline">\(\nabla_Y X = 0\)</span> (i.e., <span
    class="math inline">\(X\)</span> is covariantly constant), then the
    two derivatives are the same. This is the case when <span
    class="math inline">\(X\)</span> has constant components in
    Cartesian coordinates, like <span
    class="math inline">\(X=\frac{\partial}{\partial x^k}\)</span> for
    some <span class="math inline">\(k\)</span>. For more general vector
    fields, the two derivatives won’t necessarily be equal.</p>
    <p><strong>Key takeaway:</strong> While the coordinate expressions
    happen to coincide in <span class="math inline">\(E^n\)</span> with
    Cartesian coordinates and constant component vector fields, don’t be
    fooled! The Lie derivative and the covariant derivative are distinct
    concepts with different geometric interpretations. This equality is
    a result of the specific flat geometry of <span
    class="math inline">\(E^n\)</span> and the choice of coordinates. On
    a general manifold with a non-flat connection, the coordinate
    expressions will be different, and the conceptual differences will
    be much more apparent.</p>
    <p><strong>Clearly, <span class="math inline">\(\nabla_X Y\)</span>
    is also a vector field. Correct?</strong></p>
    <p>Yes, you are absolutely correct. <span
    class="math inline">\(\nabla_X Y\)</span> is a vector field. It
    assigns a tangent vector to each point on the manifold (or at least
    to the points where both <span class="math inline">\(X\)</span> and
    <span class="math inline">\(Y\)</span> are defined, and in the
    context of <span class="math inline">\(X\)</span> being a vector
    field along a curve, to each point on the curve).</p>
    <h1 id="covariant-derivatrive-5---product-rule">Covariant
    Derivatrive 5 - Product Rule</h1>
    <p><strong>Let <span class="math inline">\(f\)</span> be a <span
    class="math inline">\(C^{\infty} (E^n)\)</span> function. What is
    the expression for <span class="math inline">\(\nabla_X
    (fY)\)</span>? Provide details</strong></p>
    <p>Here’s the derivation of the expression for <span
    class="math inline">\(\nabla_X(fY)\)</span>, where <span
    class="math inline">\(f\)</span> is a smooth function and <span
    class="math inline">\(X\)</span> and <span
    class="math inline">\(Y\)</span> are vector fields on <span
    class="math inline">\(E^n\)</span>:</p>
    <ol type="1">
    <li><strong>Definition in <span
    class="math inline">\(\mathbf{E^n}\)</span>:</strong></li>
    </ol>
    <p>Recall that in <span class="math inline">\(E^n\)</span> with
    Cartesian coordinates, the covariant derivative is defined as:</p>
    <p><span class="math inline">\(\nabla_X Y = \sum_{i=1}^n X(Y^i)
    \frac{\partial}{\partial x^i} = \sum_{i, j=1}^n X^j \frac{\partial
    Y^i}{\partial x^j} \frac{\partial}{\partial x^i}\)</span></p>
    <ol start="2" type="1">
    <li><strong>Applying to <span
    class="math inline">\(\mathbf{fY}\)</span>:</strong></li>
    </ol>
    <p>Now, let’s replace <span class="math inline">\(Y\)</span> with
    <span class="math inline">\(fY\)</span>:</p>
    <p><span class="math inline">\(\nabla_X (fY) = \sum_{i=1}^n
    X((fY)^i) \frac{\partial}{\partial x^i}\)</span></p>
    <p>The components of <span class="math inline">\(fY\)</span> are
    given by <span class="math inline">\((fY)^i = f Y^i\)</span>.
    So,</p>
    <p><span class="math inline">\(\nabla_X (fY) = \sum_{i=1}^n X(fY^i)
    \frac{\partial}{\partial x^i}\)</span></p>
    <ol start="3" type="1">
    <li><strong>Product Rule for Derivations:</strong></li>
    </ol>
    <p><span class="math inline">\(X\)</span> acts as a derivation,
    which means it satisfies the product rule: <span
    class="math inline">\(X(gh) = X(g)h + gX(h)\)</span> for any smooth
    functions <span class="math inline">\(g\)</span> and <span
    class="math inline">\(h\)</span>. Applying this to <span
    class="math inline">\(fY^i\)</span>:</p>
    <p><span class="math inline">\(X(fY^i) = X(f)Y^i +
    fX(Y^i)\)</span></p>
    <ol start="4" type="1">
    <li><strong>Substituting Back:</strong></li>
    </ol>
    <p>Substituting this back into our expression for the covariant
    derivative:</p>
    <p><span class="math inline">\(\nabla_X (fY) = \sum_{i=1}^n \left(
    X(f)Y^i + fX(Y^i) \right) \frac{\partial}{\partial x^i}\)</span></p>
    <ol start="5" type="1">
    <li><strong>Separating Terms:</strong></li>
    </ol>
    <p>We can separate the terms in the summation:</p>
    <p><span class="math inline">\(\nabla_X (fY) = \sum_{i=1}^n X(f)Y^i
    \frac{\partial}{\partial x^i} + \sum_{i=1}^n fX(Y^i)
    \frac{\partial}{\partial x^i}\)</span></p>
    <ol start="6" type="1">
    <li><strong>Recognizing <span
    class="math inline">\(\mathbf{Y}\)</span> and <span
    class="math inline">\(\mathbf{\nabla_X Y}\)</span>:</strong></li>
    </ol>
    <p>Notice that the first term is just <span
    class="math inline">\(X(f)\)</span> multiplied by the vector field
    <span class="math inline">\(Y\)</span>, and the second term is <span
    class="math inline">\(f\)</span> multiplied by the covariant
    derivative <span class="math inline">\(\nabla_X Y\)</span>:</p>
    <p><span class="math inline">\(\nabla_X (fY) = X(f)Y + f\nabla_X
    Y\)</span></p>
    <p>Therefore, we have the final expression:</p>
    <p><span class="math inline">\(\nabla_X (fY) = X(f)Y + f\nabla_X
    Y\)</span></p>
    <p>This result shows that the covariant derivative satisfies a
    Leibniz-like rule (product rule) with respect to scalar
    multiplication. This property is one of the defining characteristics
    of a connection.</p>
    <h1 id="covariant-derivative-6---metric-compatibility">Covariant
    Derivative 6 - Metric compatibility</h1>
    <p><strong>Let <span class="math inline">\(X,Y,Z\)</span> be vector
    fields on <span class="math inline">\(E^n\)</span>. Consider <span
    class="math inline">\(X \langle Y, Z \rangle\)</span>. At a point
    <span class="math inline">\(p \in E^n\)</span>, the inner product
    evaluates to a real number. If <span
    class="math inline">\(p\)</span> is allowed to vary then the inner
    product is a scalar valued function on <span
    class="math inline">\(E^n\)</span> which is smooth. Then the term
    <span class="math inline">\(X \langle Y, Z \rangle\)</span> can be
    viewed as the directional derivative of the inner product function
    in the direction of <span class="math inline">\(X\)</span>. Is this
    correct?</strong></p>
    <p>Yes, you are absolutely correct. <span
    class="math inline">\(X\langle Y, Z \rangle\)</span> can indeed be
    interpreted as the directional derivative of the scalar function
    <span class="math inline">\(\langle Y, Z \rangle\)</span> in the
    direction of the vector field <span
    class="math inline">\(X\)</span>.</p>
    <p>Here’s a more detailed breakdown:</p>
    <ol type="1">
    <li><p><strong>Inner Product as a Smooth Function:</strong> As you
    correctly pointed out, the inner product <span
    class="math inline">\(\langle Y, Z \rangle\)</span> at a point <span
    class="math inline">\(p\)</span> gives a real number. As <span
    class="math inline">\(p\)</span> varies, <span
    class="math inline">\(\langle Y, Z \rangle\)</span> defines a smooth
    scalar function on <span class="math inline">\(E^n\)</span> (or at
    least wherever <span class="math inline">\(Y\)</span> and <span
    class="math inline">\(Z\)</span> are defined). Let’s call this
    function <span class="math inline">\(g(p) = \langle Y_p, Z_p
    \rangle\)</span>.</p></li>
    <li><p><strong><span class="math inline">\(\mathbf{X}\)</span> as a
    Derivation:</strong> A vector field <span
    class="math inline">\(X\)</span> on <span
    class="math inline">\(E^n\)</span> can be viewed as a derivation,
    which means it acts on smooth functions to produce other smooth
    functions. The action of <span class="math inline">\(X\)</span> on a
    smooth function <span class="math inline">\(f\)</span> at a point
    <span class="math inline">\(p\)</span> is given by:</p>
    <p><span class="math inline">\((Xf)(p) = X_p(f)\)</span></p>
    <p>where <span class="math inline">\(X_p\)</span> is the tangent
    vector of <span class="math inline">\(X\)</span> at <span
    class="math inline">\(p\)</span>, and it acts on <span
    class="math inline">\(f\)</span> as a directional
    derivative.</p></li>
    <li><p><strong>Directional Derivative:</strong> Thus, when we write
    <span class="math inline">\(X\langle Y, Z \rangle\)</span>, we are
    effectively taking the directional derivative of the scalar function
    <span class="math inline">\(g(p) = \langle Y, Z \rangle\)</span> in
    the direction of <span class="math inline">\(X\)</span>. At a point
    <span class="math inline">\(p\)</span>, this is:</p>
    <p><span class="math inline">\((X\langle Y, Z \rangle)(p) =
    X_p(\langle Y, Z \rangle) = X_p(g)\)</span></p>
    <p>This tells us how the value of the inner product <span
    class="math inline">\(\langle Y, Z \rangle\)</span> changes as we
    move infinitesimally from <span class="math inline">\(p\)</span> in
    the direction specified by <span
    class="math inline">\(X_p\)</span>.</p></li>
    </ol>
    <p>In coordinates, this can be expressed as:</p>
    <p><span class="math inline">\(X\langle Y, Z \rangle = \sum_{i=1}^n
    X^i \frac{\partial}{\partial x^i} \langle Y, Z \rangle =
    \sum_{i,j=1}^n X^i \frac{\partial}{\partial x^i} (Y^j Z^j)\)</span>
    (using the standard inner product in Cartesian coordinates)</p>
    <p>So your interpretation is perfectly accurate, both conceptually
    and in terms of its coordinate expression.</p>
    <p><strong>Prove this: <span class="math inline">\(X \langle Y, Z
    \rangle = \langle \nabla_X Y, Z \rangle + \langle Y, \nabla_X Z
    \rangle\)</span>. Provide details.</strong></p>
    <p>You’re asking for a proof of the metric compatibility property of
    the covariant derivative, specifically in <span
    class="math inline">\(E^n\)</span> with the standard flat
    connection. Here’s the proof:</p>
    <ol type="1">
    <li><strong>Coordinate Expressions:</strong></li>
    </ol>
    <p>Let’s express our vector fields in Cartesian coordinates:</p>
    <ul>
    <li><span class="math inline">\(X = \sum_{i=1}^n X^i
    \frac{\partial}{\partial x^i}\)</span></li>
    <li><span class="math inline">\(Y = \sum_{j=1}^n Y^j
    \frac{\partial}{\partial x^j}\)</span></li>
    <li><span class="math inline">\(Z = \sum_{k=1}^n Z^k
    \frac{\partial}{\partial x^k}\)</span></li>
    </ul>
    <p>The standard inner product in these coordinates is:</p>
    <p><span class="math inline">\(\langle Y, Z \rangle = \sum_{j=1}^n
    Y^j Z^j\)</span></p>
    <ol start="2" type="1">
    <li><strong>Left-Hand Side:</strong></li>
    </ol>
    <p>We want to compute <span class="math inline">\(X\langle Y, Z
    \rangle\)</span>. As discussed before, <span
    class="math inline">\(X\)</span> acts as a derivation:</p>
    <p><span class="math inline">\(X\langle Y, Z \rangle = \sum_{i=1}^n
    X^i \frac{\partial}{\partial x^i} \left( \sum_{j=1}^n Y^j Z^j
    \right)\)</span></p>
    <p>Using the product rule for differentiation:</p>
    <p><span class="math inline">\(X\langle Y, Z \rangle =
    \sum_{i,j=1}^n X^i \left( \frac{\partial Y^j}{\partial x^i} Z^j +
    Y^j \frac{\partial Z^j}{\partial x^i} \right) =  \sum_{i,j=1}^n  X^i
    \frac{\partial Y^j}{\partial x^i} Z^j +  \sum_{i,j=1}^n X^i Y^j
    \frac{\partial Z^j}{\partial x^i}\)</span></p>
    <ol start="3" type="1">
    <li><strong>Right-Hand Side:</strong></li>
    </ol>
    <p>Now let’s compute <span class="math inline">\(\langle \nabla_X Y,
    Z \rangle + \langle Y, \nabla_X Z \rangle\)</span>. Recall the
    expression for the covariant derivative in <span
    class="math inline">\(E^n\)</span>:</p>
    <p><span class="math inline">\(\nabla_X Y = \sum_{i,j=1}^n X^i
    \frac{\partial Y^j}{\partial x^i} \frac{\partial}{\partial
    x^j}\)</span></p>
    <p>So,</p>
    <p><span class="math inline">\(\langle \nabla_X Y, Z \rangle =
    \left\langle \sum_{i,j=1}^n X^i \frac{\partial Y^j}{\partial x^i}
    \frac{\partial}{\partial x^j} , \sum_{k=1}^n Z^k
    \frac{\partial}{\partial x^k} \right\rangle\)</span></p>
    <p>Since <span class="math inline">\(\langle
    \frac{\partial}{\partial x^j}, \frac{\partial}{\partial x^k} \rangle
    = \delta_{jk}\)</span> (Kronecker delta), this simplifies to:</p>
    <p><span class="math inline">\(\langle \nabla_X Y, Z \rangle =
    \sum_{i,j=1}^n X^i \frac{\partial Y^j}{\partial x^i}
    Z^j\)</span></p>
    <p>Similarly,</p>
    <p><span class="math inline">\(\langle Y, \nabla_X Z \rangle =
    \sum_{i,j=1}^n X^i Y^j \frac{\partial Z^j}{\partial
    x^i}\)</span></p>
    <ol start="4" type="1">
    <li><strong>Comparison:</strong></li>
    </ol>
    <p>Comparing the expressions we obtained for the left-hand side and
    the right-hand side:</p>
    <p><span class="math inline">\(X\langle Y, Z \rangle =
    \sum_{i,j=1}^n  X^i \frac{\partial Y^j}{\partial x^i} Z^j
    +  \sum_{i,j=1}^n X^i Y^j \frac{\partial Z^j}{\partial
    x^i}\)</span></p>
    <p><span class="math inline">\(\langle \nabla_X Y, Z \rangle +
    \langle Y, \nabla_X Z \rangle = \sum_{i,j=1}^n X^i \frac{\partial
    Y^j}{\partial x^i} Z^j + \sum_{i,j=1}^n X^i Y^j \frac{\partial
    Z^j}{\partial x^i}\)</span></p>
    <p>The expressions are identical. Therefore, we have proven
    that:</p>
    <p><span class="math inline">\(X\langle Y, Z \rangle = \langle
    \nabla_X Y, Z \rangle + \langle Y, \nabla_X Z \rangle\)</span></p>
    <p>This property is called <em>metric compatibility</em>. It means
    that the covariant derivative preserves the inner product. This is a
    consequence of our definition of the covariant derivative in <span
    class="math inline">\(E^n\)</span> and the fact that the connection
    is flat.</p>
    <h1 id="vector-field-along-an-open-set-in-a-hypersurface">Vector
    Field ALONG an open set in a hypersurface</h1>
    <p>We need to separate the definition into two cases: tangent vector
    fields and normal vector fields. A general vector field along O
    would be a linear combination of these.</p>
    <p><strong>Definition 1: Tangent Vector Field along O</strong></p>
    <p>Let <span class="math inline">\(M\)</span> be a hypersurface in
    <span class="math inline">\(\mathbb{E}^n\)</span>, and let <span
    class="math inline">\(O \subset M\)</span> be an open subset. A
    <em>tangent</em> vector field <span class="math inline">\(X\)</span>
    along <span class="math inline">\(O\)</span> is a smooth map <span
    class="math inline">\(X: O \to T\mathbb{E}^n\)</span> such that:</p>
    <ol type="1">
    <li><span class="math inline">\(\pi \circ X = \iota\)</span>, where
    <span class="math inline">\(\pi: T\mathbb{E}^n \to
    \mathbb{E}^n\)</span> is the canonical projection and <span
    class="math inline">\(\iota: O \hookrightarrow \mathbb{E}^n\)</span>
    is the inclusion map.</li>
    <li>For all <span class="math inline">\(p \in O\)</span>, <span
    class="math inline">\(X(p) \in T_p M\)</span>.</li>
    </ol>
    <p><strong>Definition 2: Normal Vector Field along O</strong></p>
    <p>Let <span class="math inline">\(M\)</span> be a hypersurface in
    <span class="math inline">\(\mathbb{E}^n\)</span>, and let <span
    class="math inline">\(O \subset M\)</span> be an open subset. A
    <em>normal</em> vector field <span class="math inline">\(N\)</span>
    along <span class="math inline">\(O\)</span> is a smooth map <span
    class="math inline">\(N: O \to T\mathbb{E}^n\)</span> such that:</p>
    <ol type="1">
    <li><span class="math inline">\(\pi \circ N = \iota\)</span>, where
    <span class="math inline">\(\pi: T\mathbb{E}^n \to
    \mathbb{E}^n\)</span> is the canonical projection and <span
    class="math inline">\(\iota: O \hookrightarrow \mathbb{E}^n\)</span>
    is the inclusion map.</li>
    <li>For all <span class="math inline">\(p \in O\)</span>, <span
    class="math inline">\(N(p) \in (T_p M)^{\perp}\)</span>, where <span
    class="math inline">\((T_p M)^{\perp}\)</span> denotes the
    orthogonal complement of <span class="math inline">\(T_p M\)</span>
    in <span class="math inline">\(\mathbb{E}^n\)</span>. This means
    <span class="math inline">\(\langle N(p), v \rangle = 0\)</span> for
    all <span class="math inline">\(v \in T_p M\)</span>.</li>
    </ol>
    <p><strong>Definition 3: General Vector Field along O
    (Informal)</strong></p>
    <p>A general vector field along <span
    class="math inline">\(O\)</span> can be considered as a combination
    of a tangent and a normal vector field, which can be locally
    expressed as a linear combination of a tangent vector field and a
    normal vector field. A fully rigorous definition would involve the
    splitting of the tangent bundle of the ambient space into tangent
    and normal bundles along <span class="math inline">\(O\)</span>,
    which is more advanced. For a hypersurface, the normal bundle is
    1-dimensional. A general vector field <span
    class="math inline">\(V\)</span> along <span
    class="math inline">\(O\)</span> could then be written as <span
    class="math inline">\(V = X + aN\)</span>, where <span
    class="math inline">\(X\)</span> is a tangent vector field, <span
    class="math inline">\(N\)</span> is a unit normal vector field and
    <span class="math inline">\(a:O \to \mathbb{R}\)</span> is a scalar
    function. The smoothness of V would depend on the smoothness of X, N
    and a.</p>
    <p>The “smoothness” of X and N in Definitions 1 and 2 can be
    rigorously defined either via local coordinates or by requiring
    smoothness of the composition with any smooth curve in O, as
    discussed previously.</p>
    <p><strong>Condition 1 assures that the vector chosen by <span
    class="math inline">\(X\)</span> is anchored at the same point <span
    class="math inline">\(p\)</span> on which <span
    class="math inline">\(X\)</span> acts. Is this correct?</strong></p>
    <p>Yes, that’s precisely correct. Condition 1, <span
    class="math inline">\(\pi \circ X = \iota\)</span>, ensures that the
    vector <span class="math inline">\(X(p)\)</span> is based at the
    point <span class="math inline">\(p \in O\)</span>. The projection
    map <span class="math inline">\(\pi\)</span> takes a tangent vector
    and returns its base point. The inclusion map <span
    class="math inline">\(\iota\)</span> simply embeds <span
    class="math inline">\(O\)</span> into <span
    class="math inline">\(\mathbb{E}^n\)</span>. The condition states
    that the base point of the vector <span
    class="math inline">\(X(p)\)</span> is the same as the point <span
    class="math inline">\(p\)</span> on the hypersurface.</p>
    <h1 id="local-coordinates-adapted-to-hypersurface">Local coordinates
    adapted to hypersurface</h1>
    <p>The intuition behind a chart adapted to a hypersurface <span
    class="math inline">\(M\)</span> is that it provides a coordinate
    system that’s “naturally aligned” with the geometry of <span
    class="math inline">\(M\)</span>. A standard chart on the ambient
    space <span class="math inline">\(\mathbb{E}^n\)</span> treats <span
    class="math inline">\(M\)</span> as just a subset; it doesn’t
    inherently capture the intrinsic dimensionality and structure of
    <span class="math inline">\(M\)</span>. An adapted chart, however,
    does.</p>
    <p>Here’s the key intuition:</p>
    <ul>
    <li><p><strong>Intrinsic Dimensionality:</strong> A hypersurface
    <span class="math inline">\(M\)</span> in <span
    class="math inline">\(\mathbb{E}^n\)</span> has dimension <span
    class="math inline">\(n-1\)</span>. An adapted chart uses only <span
    class="math inline">\(n-1\)</span> coordinates to describe points on
    <span class="math inline">\(M\)</span>, reflecting this intrinsic
    dimensionality. In contrast, a chart on <span
    class="math inline">\(\mathbb{E}^n\)</span> would use <span
    class="math inline">\(n\)</span> coordinates, even when restricted
    to <span class="math inline">\(M\)</span>, which carries extra,
    extrinsic information that’s unnecessary to describe the geometry of
    <span class="math inline">\(M\)</span> alone.</p></li>
    <li><p><strong>Tangential Coordinates:</strong> Intuitively, the
    coordinates in an adapted chart are chosen to lie “along” the
    surface. They essentially measure distances along directions tangent
    to the surface. Think of drawing a coordinate grid directly onto the
    surface; these are your adapted coordinates. This is in contrast to
    a standard coordinate system where the coordinates may not align
    with the surface; they’re “extrinsic” coordinates.</p></li>
    <li><p><strong>Simplification of Calculations:</strong> Using an
    adapted chart simplifies calculations involving objects
    intrinsically related to <span class="math inline">\(M\)</span>,
    such as tangent vectors, normal vectors, and the first fundamental
    form. Calculations become much cleaner because you’re working
    directly with coordinates that are naturally suited to the surface’s
    geometry. You avoid the redundancy of an extra coordinate that adds
    nothing meaningful to the surface’s geometry.</p></li>
    </ul>
    <p>In essence, an adapted chart gives you a coordinate system that’s
    perfectly suited to working with the intrinsic geometry of the
    hypersurface, allowing for efficient calculations and a clearer
    geometric picture. You only need the minimum number of coordinates
    to describe a point on the surface, and these coordinates directly
    relate to the surface’s local structure.</p>
    <p><strong>Let <span class="math inline">\(M\)</span> be a regular
    hypersurface in <span class="math inline">\(E^n\)</span>. Let <span
    class="math inline">\(p \in M \subset E^n\)</span> be a point on
    <span class="math inline">\(M\)</span>. Construct a chart on an open
    set around <span class="math inline">\(p\)</span> which is adapted
    to <span class="math inline">\(M\)</span></strong></p>
    <p><strong>1. The Setup:</strong></p>
    <p>Since <span class="math inline">\(M\)</span> is a regular
    hypersurface in <span class="math inline">\(E^n\)</span>, for any
    <span class="math inline">\(p \in M\)</span>, there exists an open
    set <span class="math inline">\(U \subset E^n\)</span> containing
    <span class="math inline">\(p\)</span>, an open set <span
    class="math inline">\(V \subset \mathbb{R}^n\)</span>, and a smooth
    diffeomorphism <span class="math inline">\(\phi: U \to V\)</span>
    such that <span class="math inline">\(\phi(M \cap U) = V \cap
    (\mathbb{R}^{n-1} \times \{0\})\)</span>.</p>
    <p><strong>2. Constructing the Chart:</strong></p>
    <p>We want to construct a chart <span
    class="math inline">\((\tilde{U}, \psi)\)</span> where <span
    class="math inline">\(\tilde{U} \subset M\)</span> is open and
    contains <span class="math inline">\(p\)</span>, and <span
    class="math inline">\(\psi: \tilde{U} \to \tilde{V} \subset
    \mathbb{R}^{n-1}\)</span> is a homeomorphism onto an open set <span
    class="math inline">\(\tilde{V}\)</span>.</p>
    <p>Let <span class="math inline">\(\pi: \mathbb{R}^n \to
    \mathbb{R}^{n-1}\)</span> be the projection onto the first <span
    class="math inline">\(n-1\)</span> coordinates: <span
    class="math inline">\(\pi(x_1, \dots, x_n) = (x_1, \dots,
    x_{n-1})\)</span>.</p>
    <p>Define <span class="math inline">\(\tilde{U} = M \cap U\)</span>.
    This is an open set in <span class="math inline">\(M\)</span>
    containing <span class="math inline">\(p\)</span>.</p>
    <p>Now define <span class="math inline">\(\psi: \tilde{U} \to
    \mathbb{R}^{n-1}\)</span> by <span class="math inline">\(\psi = \pi
    \circ \phi|_{\tilde{U}}\)</span>. That is, restrict <span
    class="math inline">\(\phi\)</span> to <span
    class="math inline">\(\tilde{U}\)</span> and then project onto the
    first <span class="math inline">\(n-1\)</span> coordinates. Let
    <span class="math inline">\(\tilde{V} = \psi(\tilde{U})\)</span>.
    Since <span class="math inline">\(\phi\)</span> is a diffeomorphism,
    and <span class="math inline">\(\pi\)</span> when restricted to
    <span class="math inline">\(V \cap (\mathbb{R}^{n-1} \times
    \{0\})\)</span> is a diffeomorphism, <span
    class="math inline">\(\tilde{V}\)</span> will be open in <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span>.</p>
    <p><strong>3. Verification:</strong></p>
    <ul>
    <li><p><strong>Smoothness:</strong> <span
    class="math inline">\(\psi\)</span> is smooth as it is a composition
    of smooth maps (<span class="math inline">\(\pi\)</span> and the
    restriction of <span class="math inline">\(\phi\)</span>).</p></li>
    <li><p><strong>Homeomorphism:</strong> Because <span
    class="math inline">\(\phi\)</span> maps <span
    class="math inline">\(M \cap U\)</span> diffeomorphically onto <span
    class="math inline">\(V \cap (\mathbb{R}^{n-1} \times
    \{0\})\)</span> and <span class="math inline">\(\pi\)</span>
    restricted to <span class="math inline">\(V \cap (\mathbb{R}^{n-1}
    \times \{0\})\)</span> gives a diffeomorphism to an open set in
    <span class="math inline">\(\mathbb{R}^{n-1}\)</span>, the
    composition <span class="math inline">\(\psi\)</span> provides the
    required homeomorphism between <span
    class="math inline">\(\tilde{U}\)</span> and <span
    class="math inline">\(\tilde{V}\)</span>.</p></li>
    <li><p><strong>Open Sets:</strong> <span
    class="math inline">\(\tilde{U}\)</span> is open in <span
    class="math inline">\(M\)</span> by definition. <span
    class="math inline">\(\tilde{V}\)</span> is open in <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span> as discussed
    above.</p></li>
    </ul>
    <p>Therefore, <span class="math inline">\((\tilde{U}, \psi)\)</span>
    is a chart on <span class="math inline">\(M\)</span> around <span
    class="math inline">\(p\)</span>, and this chart is adapted to <span
    class="math inline">\(M\)</span>. This construction ensures that
    <span class="math inline">\(\psi\)</span> maps a neighborhood of
    <span class="math inline">\(p\)</span> in <span
    class="math inline">\(M\)</span> to an open set in <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span>, effectively
    “flattening” the hypersurface locally.</p>
    <p><strong>I understand the intuition. I need a rigorous explanation
    for <span class="math inline">\(\phi(U \cap M) = V \cap (R^{n-1}
    \times \{0\})\)</span></strong></p>
    <p>You’re right to push for rigor. The statement <span
    class="math inline">\(\phi(U \cap M) = V \cap (\mathbb{R}^{n-1}
    \times \{0\})\)</span> is a <em>direct consequence</em> of the
    definition of a regular submanifold, and thus a regular
    hypersurface. Here’s a rigorous breakdown, referencing the
    definition explicitly:</p>
    <p><strong>1. Definition of a Regular Submanifold:</strong></p>
    <p>One common definition of a regular <span
    class="math inline">\(k\)</span>-dimensional submanifold <span
    class="math inline">\(M\)</span> of an <span
    class="math inline">\(n\)</span>-dimensional manifold <span
    class="math inline">\(N\)</span> is as follows: For every point
    <span class="math inline">\(p \in M\)</span>, there exists a chart
    <span class="math inline">\((U, \phi)\)</span> of <span
    class="math inline">\(N\)</span> with <span class="math inline">\(p
    \in U\)</span> such that:</p>
    <p><span class="math display">\[ \phi(U \cap M) = \phi(U) \cap
    (\mathbb{R}^k \times \{0\}^{n-k}) \]</span></p>
    <p>Here, <span class="math inline">\(\{0\}^{n-k}\)</span> denotes
    the <span class="math inline">\((n-k)\)</span>-tuple <span
    class="math inline">\((0, 0, ..., 0)\)</span>.</p>
    <p><strong>2. Applying the Definition to a
    Hypersurface:</strong></p>
    <p>A hypersurface is simply a submanifold of codimension 1. This
    means that for our hypersurface <span
    class="math inline">\(M\)</span> in <span
    class="math inline">\(E^n\)</span> (which we can treat locally as
    <span class="math inline">\(\mathbb{R}^n\)</span>), the dimension
    <span class="math inline">\(k\)</span> is <span
    class="math inline">\(n-1\)</span>. Substituting this into the
    definition above, we get:</p>
    <p><span class="math display">\[ \phi(U \cap M) = \phi(U) \cap
    (\mathbb{R}^{n-1} \times \{0\}) \]</span></p>
    <p><strong>3. Defining <span
    class="math inline">\(V\)</span>:</strong></p>
    <p>Since <span class="math inline">\(\phi\)</span> is a
    diffeomorphism from <span class="math inline">\(U\)</span> to an
    open set in <span class="math inline">\(\mathbb{R}^n\)</span>, we
    can denote <span class="math inline">\(\phi(U)\)</span> as <span
    class="math inline">\(V\)</span>. <span
    class="math inline">\(V\)</span> is then an open set in <span
    class="math inline">\(\mathbb{R}^n\)</span>. Substituting <span
    class="math inline">\(V\)</span> into the equation, we arrive at
    precisely the statement we’re examining:</p>
    <p><span class="math display">\[ \phi(U \cap M) = V \cap
    (\mathbb{R}^{n-1} \times \{0\}) \]</span></p>
    <p><strong>4. Why this definition is chosen:</strong></p>
    <p>This definition formalizes the intuitive notion of “flattening
    out” the submanifold locally. The chart <span
    class="math inline">\(\phi\)</span> essentially “straightens” the
    curved hypersurface within <span class="math inline">\(U\)</span> so
    that it becomes a flat piece of <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span> embedded in <span
    class="math inline">\(\mathbb{R}^n\)</span>. This flat piece is
    represented by <span class="math inline">\(\mathbb{R}^{n-1} \times
    \{0\}\)</span>, and its intersection with <span
    class="math inline">\(V\)</span> gives us precisely the image of the
    portion of the hypersurface contained in <span
    class="math inline">\(U\)</span>.</p>
    <p><strong>In summary:</strong> The equation <span
    class="math inline">\(\phi(U \cap M) = V \cap (\mathbb{R}^{n-1}
    \times \{0\})\)</span> isn’t some arbitrary condition; it’s a core
    part of the <em>definition</em> of a regular submanifold (and hence
    a regular hypersurface). It ensures the existence of a chart that
    locally represents the hypersurface as a flat Euclidean space of one
    dimension lower, which is essential for doing differential geometry
    on the hypersurface.</p>
    <p><strong>Provide more rigor and details on Step 2 regarding <span
    class="math inline">\(\tilde{V} =
    \psi(\tilde{U})\)</span>.</strong></p>
    <p>You’re right to ask for more rigor here. The key is to carefully
    examine the composition of mappings and the properties of
    diffeomorphisms to establish that <span
    class="math inline">\(\tilde{V}\)</span> is indeed an open set in
    <span class="math inline">\(\mathbb{R}^{n-1}\)</span>.</p>
    <p>Here’s a more detailed breakdown of Step 2, focusing on the
    openness of <span class="math inline">\(\tilde{V}\)</span>:</p>
    <p><strong>Step 2 (Revised and Detailed):</strong></p>
    <p>Recall that we have:</p>
    <ul>
    <li><span class="math inline">\(U \subset E^n\)</span> open,
    containing <span class="math inline">\(p\)</span>.</li>
    <li><span class="math inline">\(\phi: U \to V \subset
    \mathbb{R}^n\)</span> a diffeomorphism.</li>
    <li><span class="math inline">\(\tilde{U} = M \cap U\)</span>, open
    in <span class="math inline">\(M\)</span>.</li>
    <li><span class="math inline">\(\pi: \mathbb{R}^n \to
    \mathbb{R}^{n-1}\)</span> the projection onto the first <span
    class="math inline">\(n-1\)</span> coordinates.</li>
    <li><span class="math inline">\(\psi: \tilde{U} \to
    \mathbb{R}^{n-1}\)</span> defined by <span
    class="math inline">\(\psi = \pi \circ
    \phi|_{\tilde{U}}\)</span>.</li>
    </ul>
    <p>We want to show that <span class="math inline">\(\tilde{V} =
    \psi(\tilde{U})\)</span> is open in <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span>.</p>
    <ol type="1">
    <li><p><strong>Image of <span
    class="math inline">\(\tilde{U}\)</span> under <span
    class="math inline">\(\phi\)</span>:</strong> Since <span
    class="math inline">\(\phi\)</span> is a diffeomorphism, it’s an
    open map. This means that <span
    class="math inline">\(\phi(\tilde{U}) = \phi(M \cap U)\)</span> is
    open <em>in the subspace topology of</em> <span
    class="math inline">\(\phi(U) = V\)</span>. Critically, we know from
    the definition of a regular submanifold (as discussed earlier) that
    <span class="math inline">\(\phi(M \cap U) = V \cap
    (\mathbb{R}^{n-1} \times \{0\})\)</span>.</p></li>
    <li><p><strong>Projection of <span class="math inline">\(V \cap
    (\mathbb{R}^{n-1} \times \{0\})\)</span>:</strong> The projection
    map <span class="math inline">\(\pi\)</span> restricted to <span
    class="math inline">\(\mathbb{R}^{n-1} \times \{0\}\)</span> is
    simply the identity map onto <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span>, and hence a
    homeomorphism (indeed, a diffeomorphism). Let’s denote this
    restricted projection as <span class="math inline">\(\pi&#39;:
    \mathbb{R}^{n-1} \times \{0\} \to
    \mathbb{R}^{n-1}\)</span>.</p></li>
    <li><p><strong><span class="math inline">\(\tilde{V}\)</span> is
    open:</strong> We have <span class="math inline">\(\tilde{V} =
    \psi(\tilde{U}) = \pi(\phi(\tilde{U})) = \pi(V \cap
    (\mathbb{R}^{n-1} \times \{0\}))\)</span>. Because <span
    class="math inline">\(V \cap (\mathbb{R}^{n-1} \times
    \{0\})\)</span> can be thought of as an open subset of <span
    class="math inline">\(\mathbb{R}^{n-1} \times \{0\}\)</span>, and
    <span class="math inline">\(\pi&#39;\)</span> (the restriction of
    <span class="math inline">\(\pi\)</span>) is a homeomorphism
    (diffeomorphism, in fact), the image <span
    class="math inline">\(\tilde{V}\)</span> must be open in <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span>.</p></li>
    </ol>
    <p><strong>In essence:</strong></p>
    <p>The argument hinges on the fact that <span
    class="math inline">\(\phi\)</span> maps <span
    class="math inline">\(\tilde{U}\)</span> to an open set
    <em>within</em> <span class="math inline">\(V \cap (\mathbb{R}^{n-1}
    \times \{0\})\)</span>, and the projection <span
    class="math inline">\(\pi\)</span>, when restricted to <span
    class="math inline">\(\mathbb{R}^{n-1} \times \{0\}\)</span>, is a
    diffeomorphism onto <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span>. Therefore, the
    composition of these maps, which is <span
    class="math inline">\(\psi\)</span>, maps <span
    class="math inline">\(\tilde{U}\)</span> onto an open set <span
    class="math inline">\(\tilde{V}\)</span> in <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span>. This makes <span
    class="math inline">\((\tilde{U}, \psi)\)</span> a valid chart.</p>
    <p><strong>What is the intuition behind the adapted chart <span
    class="math inline">\((\tilde{U}, \psi)\)</span>? It has <span
    class="math inline">\((n-1)\)</span> coordinates as expected. Can we
    think of a grid being painted onto <span
    class="math inline">\(M\)</span>?</strong></p>
    <p>Yes, the intuition of a painted grid is excellent! The adapted
    chart <span class="math inline">\((\tilde{U}, \psi)\)</span>
    essentially provides a way to “paint” a local <span
    class="math inline">\((n-1)\)</span>-dimensional coordinate grid
    onto the <span class="math inline">\(n\)</span>-dimensional
    hypersurface <span class="math inline">\(M\)</span>.</p>
    <p>Here’s how to visualize it:</p>
    <ol type="1">
    <li><p><strong>The Hypersurface:</strong> Imagine <span
    class="math inline">\(M\)</span> as a curved surface (if <span
    class="math inline">\(n=3\)</span>) or a higher-dimensional analogue
    embedded in a higher-dimensional space.</p></li>
    <li><p><strong>The Neighborhood <span
    class="math inline">\(\tilde{U}\)</span>:</strong> <span
    class="math inline">\(\tilde{U}\)</span> is a small patch of this
    hypersurface around the point <span
    class="math inline">\(p\)</span>. Think of it as the region where we
    want to paint our grid.</p></li>
    <li><p><strong>The Chart Map <span
    class="math inline">\(\psi\)</span>:</strong> The chart map <span
    class="math inline">\(\psi: \tilde{U} \to \tilde{V} \subset
    \mathbb{R}^{n-1}\)</span> acts like the painting process. It assigns
    to each point on the patch <span
    class="math inline">\(\tilde{U}\)</span> a unique set of <span
    class="math inline">\((n-1)\)</span> coordinates, which are just the
    coordinates in <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span>.</p></li>
    <li><p><strong>The Coordinate Grid:</strong> The coordinates
    assigned by <span class="math inline">\(\psi\)</span> form a grid on
    <span class="math inline">\(\tilde{U}\)</span>. If you were to draw
    lines of constant coordinates (like lines of latitude and longitude
    on a globe), you would get a grid that conforms to the curvature of
    the hypersurface within <span
    class="math inline">\(\tilde{U}\)</span>.</p></li>
    <li><p><strong>Flattening:</strong> Crucially, because <span
    class="math inline">\(\psi\)</span> is a homeomorphism (and part of
    a smooth structure, meaning it’s compatible with other charts), this
    grid is “smooth” and doesn’t get crumpled or folded. It locally
    “flattens” the curved hypersurface, allowing us to use the standard
    calculus of <span class="math inline">\(\mathbb{R}^{n-1}\)</span> to
    analyze the geometry of <span class="math inline">\(M\)</span>
    within <span class="math inline">\(\tilde{U}\)</span>.</p></li>
    </ol>
    <p><strong>Example (Surface in 3D):</strong></p>
    <p>If <span class="math inline">\(M\)</span> is a 2D surface in
    <span class="math inline">\(\mathbb{R}^3\)</span>, then <span
    class="math inline">\(\psi\)</span> maps a patch of the surface to a
    region in <span class="math inline">\(\mathbb{R}^2\)</span>. Imagine
    drawing a grid on a piece of paper (representing <span
    class="math inline">\(\mathbb{R}^2\)</span>) and then smoothly
    gluing that paper onto the surface. The lines of the grid, now on
    the surface, become the coordinate lines of the chart, and they
    provide a local coordinate system for the surface patch.</p>
    <p><strong>Why <span class="math inline">\((n-1)\)</span>
    coordinates?</strong></p>
    <p>A hypersurface has dimension <span
    class="math inline">\((n-1)\)</span>, meaning it locally looks like
    <span class="math inline">\(\mathbb{R}^{n-1}\)</span>. Therefore, we
    only need <span class="math inline">\((n-1)\)</span> coordinates to
    specify a point within a small neighborhood on the hypersurface. The
    adapted chart reflects this inherent dimensionality.</p>
    <p>So, the intuition of “painting a grid” is very much valid! The
    adapted chart provides a systematic and rigorous way to define a
    local coordinate system that respects the curvature of the
    hypersurface.</p>
    <p><strong>For an arbitrary point <span class="math inline">\(p \in
    M \subset E^n\)</span>, we can choose any chart <span
    class="math inline">\((U,\phi)\)</span> around <span
    class="math inline">\(p\)</span> to construct the adapted chart
    <span class="math inline">\((\tilde{U}, \psi)\)</span>. Is this
    correct?</strong></p>
    <p>No, that’s not entirely correct. You can’t choose <em>any</em>
    chart <span class="math inline">\((U, \phi)\)</span> around <span
    class="math inline">\(p\)</span> in <span
    class="math inline">\(E^n\)</span> to construct an adapted chart for
    <span class="math inline">\(M\)</span>. The chart <span
    class="math inline">\((U, \phi)\)</span> must satisfy the specific
    condition that “flattens” the hypersurface locally, as we’ve
    discussed:</p>
    <p><span class="math display">\[ \phi(U \cap M) = \phi(U) \cap
    (\mathbb{R}^{n-1} \times \{0\}) \]</span></p>
    <p>Or, if we define <span class="math inline">\(V =
    \phi(U)\)</span>:</p>
    <p><span class="math display">\[ \phi(U \cap M) = V \cap
    (\mathbb{R}^{n-1} \times \{0\}) \]</span></p>
    <p>This condition is crucial because it ensures that the image of
    the hypersurface under <span class="math inline">\(\phi\)</span>
    lies in a hyperplane (<span class="math inline">\(\mathbb{R}^{n-1}
    \times \{0\}\)</span>), which allows us to use the first <span
    class="math inline">\(n-1\)</span> coordinates as local coordinates
    on <span class="math inline">\(M\)</span>.</p>
    <p>If a chart <span class="math inline">\((U, \phi)\)</span>
    <em>doesn’t</em> satisfy this condition, then <span
    class="math inline">\(\phi(U \cap M)\)</span> might be a more
    complicated subset of <span
    class="math inline">\(\mathbb{R}^n\)</span>, and we wouldn’t be able
    to define a chart for <span class="math inline">\(M\)</span> with
    <span class="math inline">\(n-1\)</span> coordinates simply by
    projecting onto the first <span class="math inline">\(n-1\)</span>
    components.</p>
    <p><strong>Why not any chart?</strong></p>
    <p>Imagine a surface <span class="math inline">\(M\)</span> in <span
    class="math inline">\(\mathbb{R}^3\)</span>. A general chart <span
    class="math inline">\((U, \phi)\)</span> for <span
    class="math inline">\(\mathbb{R}^3\)</span> just smoothly maps a
    region <span class="math inline">\(U\)</span> of <span
    class="math inline">\(\mathbb{R}^3\)</span> to a region <span
    class="math inline">\(V\)</span> of <span
    class="math inline">\(\mathbb{R}^3\)</span>. There’s no guarantee
    that the image of the surface patch <span class="math inline">\(U
    \cap M\)</span> will lie in a plane. It could be a curved surface in
    <span class="math inline">\(V\)</span>. Therefore, you can’t just
    project onto the first two coordinates to get a chart for <span
    class="math inline">\(M\)</span>. You need a chart that specifically
    “flattens” the surface locally.</p>
    <p><strong>In summary:</strong> The existence of a chart <span
    class="math inline">\((U, \phi)\)</span> satisfying the flattening
    condition is guaranteed by the definition of a regular submanifold.
    However, an <em>arbitrary</em> chart for the ambient space <span
    class="math inline">\(E^n\)</span> will not necessarily work for
    constructing an adapted chart for the hypersurface <span
    class="math inline">\(M\)</span>. You must choose a chart that
    satisfies the specific flattening condition.</p>
    <p><strong>The existence of the chart <span
    class="math inline">\((U, \phi)\)</span> is clear. How can one find
    such a chart</strong></p>
    <p>You’re right that the existence is guaranteed by the definition,
    but finding an explicit chart <span class="math inline">\((U,
    \phi)\)</span> can be challenging and depends heavily on how the
    hypersurface <span class="math inline">\(M\)</span> is defined.
    There’s no single, universally applicable method. Here are some
    common approaches:</p>
    <p><strong>1. Implicit Definition:</strong></p>
    <p>If <span class="math inline">\(M\)</span> is defined implicitly
    as the zero set of a smooth function <span class="math inline">\(f:
    E^n \to \mathbb{R}\)</span> (i.e., <span class="math inline">\(M =
    \{x \in E^n | f(x) = 0\}\)</span>), and if the gradient <span
    class="math inline">\(\nabla f\)</span> is non-zero on <span
    class="math inline">\(M\)</span>, then the Implicit Function Theorem
    provides a way to construct the chart. The theorem guarantees that
    locally, you can express one coordinate as a function of the others,
    effectively “flattening” the hypersurface.</p>
    <ul>
    <li><strong>Example:</strong> Consider the unit sphere <span
    class="math inline">\(S^2\)</span> in <span
    class="math inline">\(\mathbb{R}^3\)</span> defined by <span
    class="math inline">\(f(x, y, z) = x^2 + y^2 + z^2 - 1 = 0\)</span>.
    If we take a point <span class="math inline">\(p = (x_0, y_0,
    z_0)\)</span> on <span class="math inline">\(S^2\)</span> where
    <span class="math inline">\(z_0 \neq 0\)</span>, the Implicit
    Function Theorem tells us that near <span
    class="math inline">\(p\)</span>, we can express <span
    class="math inline">\(z\)</span> as a function of <span
    class="math inline">\(x\)</span> and <span
    class="math inline">\(y\)</span>, say <span class="math inline">\(z
    = g(x, y)\)</span>. Then the map <span class="math inline">\(\phi(x,
    y, z) = (x, y, z - g(x, y))\)</span> is a chart that flattens the
    sphere locally, mapping the portion of <span
    class="math inline">\(S^2\)</span> near <span
    class="math inline">\(p\)</span> to the <span
    class="math inline">\(xy\)</span>-plane.</li>
    </ul>
    <p><strong>2. Graph of a Function:</strong></p>
    <p>If <span class="math inline">\(M\)</span> is locally the graph of
    a smooth function <span class="math inline">\(g: \mathbb{R}^{n-1}
    \to \mathbb{R}\)</span>, meaning <span
    class="math inline">\(M\)</span> can be represented near <span
    class="math inline">\(p\)</span> as the set of points <span
    class="math inline">\((x_1, \dots, x_{n-1}, g(x_1, \dots,
    x_{n-1}))\)</span>, then a chart can be constructed directly:</p>
    <ul>
    <li><strong>The Chart:</strong> <span
    class="math inline">\(\phi(x_1, \dots, x_n) = (x_1, \dots, x_{n-1},
    x_n - g(x_1, \dots, x_{n-1}))\)</span>. This chart maps the graph of
    <span class="math inline">\(g\)</span> to the hyperplane <span
    class="math inline">\(\mathbb{R}^{n-1} \times \{0\}\)</span>.</li>
    </ul>
    <p><strong>3. Parameterization:</strong></p>
    <p>If <span class="math inline">\(M\)</span> is given by a regular
    parameterization, <span class="math inline">\(\mathbf{x}: \Omega
    \subset \mathbb{R}^{n-1} \to M \subset E^n\)</span>, where <span
    class="math inline">\(\Omega\)</span> is open, then the
    parameterization itself can often be adapted to form a chart. This
    requires verifying that the parameterization is a homeomorphism onto
    its image and that the image is open in <span
    class="math inline">\(M\)</span>.</p>
    <p><strong>4. Level Sets of Submersions:</strong></p>
    <p>More generally, if <span class="math inline">\(M\)</span> is a
    regular level set of a smooth submersion <span
    class="math inline">\(F: E^n \to \mathbb{R}^{n-k}\)</span> (where
    <span class="math inline">\(M\)</span> has dimension <span
    class="math inline">\(k\)</span>), then the preimage theorem
    combined with the inverse function theorem can be used to create
    charts that locally flatten <span class="math inline">\(M\)</span>.
    For the hypersurface case, <span
    class="math inline">\(k=n-1\)</span>.</p>
    <p><strong>5. Combination of Methods:</strong> Often, a combination
    of these techniques is necessary.</p>
    <p><strong>Important Note:</strong> Finding an explicit chart can be
    computationally intensive or even impossible to do in closed form
    for complicated hypersurfaces. However, the theoretical guarantee of
    the existence of such charts is crucial for developing the theory of
    differential geometry.</p>
    <h1 id="shape-operator">Shape Operator</h1>
    <p><strong>consider a hypersurface <span class="math inline">\(M
    \subset E^n\)</span>. Let <span class="math inline">\(N\)</span> be
    a unit normal vector field along an open set <span
    class="math inline">\(U \subset M\)</span> containing <span
    class="math inline">\(p\)</span>. For any tangent vector <span
    class="math inline">\(v_p \in T_pM\)</span>, we have the covariant
    derivative <span class="math inline">\(\nabla_{v_p} N\)</span>. It
    appears that <span class="math inline">\(\nabla_{v_p} N \in
    T_pM\)</span>. Is this correct? If so, prove this with
    details.</strong></p>
    <p>Yes, you are correct. <span class="math inline">\(\nabla_{v_p} N
    \in T_pM\)</span>. Here’s a detailed proof:</p>
    <p>Since <span class="math inline">\(N\)</span> is a unit normal
    vector field, we have <span class="math inline">\(\langle N, N
    \rangle = 1\)</span> on <span class="math inline">\(U\)</span>. We
    can take the covariant derivative of this equation along any tangent
    vector <span class="math inline">\(v_p \in T_pM\)</span>. Recall
    that the covariant derivative is compatible with the metric, meaning
    <span class="math display">\[v_p \langle N, N \rangle = \langle
    \nabla_{v_p} N, N \rangle + \langle N, \nabla_{v_p} N
    \rangle.\]</span> Since <span class="math inline">\(v_p \langle N, N
    \rangle = v_p(1) = 0\)</span> and the inner product is symmetric, we
    have <span class="math display">\[2 \langle \nabla_{v_p} N, N
    \rangle = 0,\]</span> which implies <span
    class="math display">\[\langle \nabla_{v_p} N, N \rangle =
    0.\]</span> This means that <span class="math inline">\(\nabla_{v_p}
    N\)</span> is orthogonal to <span class="math inline">\(N\)</span>
    at <span class="math inline">\(p\)</span>. Since <span
    class="math inline">\(N\)</span> is the unit normal vector to the
    hypersurface <span class="math inline">\(M\)</span> at <span
    class="math inline">\(p\)</span>, any vector orthogonal to <span
    class="math inline">\(N\)</span> at <span
    class="math inline">\(p\)</span> must be tangent to <span
    class="math inline">\(M\)</span> at <span
    class="math inline">\(p\)</span>. Therefore, <span
    class="math inline">\(\nabla_{v_p} N \in T_pM\)</span>.</p>
    <p>So, to summarize, the fact that <span
    class="math inline">\(N\)</span> is a <em>unit</em> normal vector
    field is crucial. The unit length condition <span
    class="math inline">\(\langle N, N \rangle = 1\)</span> allows us to
    take the covariant derivative and show that <span
    class="math inline">\(\nabla_{v_p} N\)</span> is orthogonal to <span
    class="math inline">\(N\)</span>, hence tangent to <span
    class="math inline">\(M\)</span> at <span
    class="math inline">\(p\)</span>.</p>
    <p><strong><span class="math inline">\(v_p\)</span> is arbitrarily
    chosen above. What is the intuition behind <span
    class="math inline">\(\nabla_{v_p} N\)</span>?</strong></p>
    <p>The intuition behind <span class="math inline">\(\nabla_{v_p}
    N\)</span> is how the normal vector <span
    class="math inline">\(N\)</span> changes as you move along the
    hypersurface <span class="math inline">\(M\)</span> in the direction
    of the tangent vector <span class="math inline">\(v_p\)</span>.
    Since <span class="math inline">\(N\)</span> is a unit vector, its
    magnitude cannot change. Therefore, the change is entirely reflected
    in the <em>direction</em> of <span
    class="math inline">\(N\)</span>.</p>
    <p>More specifically:</p>
    <ol type="1">
    <li><p><strong>Curvature:</strong> <span
    class="math inline">\(\nabla_{v_p} N\)</span> captures how the
    hypersurface <span class="math inline">\(M\)</span> curves in the
    direction of <span class="math inline">\(v_p\)</span>. If <span
    class="math inline">\(M\)</span> is flat in the direction of <span
    class="math inline">\(v_p\)</span>, then <span
    class="math inline">\(N\)</span> doesn’t change as you move in that
    direction, so <span class="math inline">\(\nabla_{v_p} N =
    0\)</span>. If <span class="math inline">\(M\)</span> curves, <span
    class="math inline">\(N\)</span> will change direction, and <span
    class="math inline">\(\nabla_{v_p} N\)</span> quantifies this
    change.</p></li>
    <li><p><strong>Tangential Component:</strong> Crucially, as we
    proved, <span class="math inline">\(\nabla_{v_p} N\)</span> lies in
    the tangent space <span class="math inline">\(T_pM\)</span>. This is
    because we’re looking at how <span class="math inline">\(N\)</span>
    changes <em>as seen by someone “living” on the hypersurface</em>.
    They can only perceive changes in directions tangent to the
    surface.</p></li>
    <li><p><strong>Shape Operator:</strong> <span
    class="math inline">\(-\nabla_{v_p} N\)</span> defines the <em>shape
    operator</em> (or Weingarten map), denoted by <span
    class="math inline">\(S(v_p)\)</span>. The shape operator is a
    linear map from <span class="math inline">\(T_pM\)</span> to <span
    class="math inline">\(T_pM\)</span>. It’s a fundamental object in
    differential geometry, encoding all the information about the
    curvature of <span class="math inline">\(M\)</span> at <span
    class="math inline">\(p\)</span>.</p></li>
    <li><p><strong>Example (Sphere):</strong> Imagine <span
    class="math inline">\(M\)</span> is a sphere in <span
    class="math inline">\(\mathbb{R}^3\)</span>. The outward-pointing
    unit normal <span class="math inline">\(N\)</span> at a point <span
    class="math inline">\(p\)</span> is just the radial vector from the
    center of the sphere to <span class="math inline">\(p\)</span>. As
    you move along any great circle (a geodesic on the sphere,
    representing a “straight line” on the surface), the normal <span
    class="math inline">\(N\)</span> rotates towards the center of the
    great circle. This rotation is precisely what <span
    class="math inline">\(\nabla_{v_p} N\)</span> captures. In this
    case, <span class="math inline">\(S(v_p) = -\nabla_{v_p} N =
    \frac{1}{r} v_p\)</span>, where <span
    class="math inline">\(r\)</span> is the radius of the sphere,
    indicating constant curvature.</p></li>
    </ol>
    <p>In summary, <span class="math inline">\(\nabla_{v_p} N\)</span>
    tells you how the normal vector field changes as you infinitesimally
    move along the hypersurface in the direction of <span
    class="math inline">\(v_p\)</span>, and this change is entirely a
    rotation within the tangent plane, reflecting the curvature of the
    hypersurface.</p>
    <h1 id="metric-on-hypersurface-m">Metric on hypersurface M</h1>
    <p><strong>For the setup as above, <span class="math inline">\(T_p M
    \subset T_p E^n\)</span>. There is the standard inner product
    defined on <span class="math inline">\(E^n\)</span> at <span
    class="math inline">\(p \in M\)</span>. Is there a notion of an
    inner product on <span class="math inline">\(M\)</span> which is a
    restriction of the standard inner product at <span
    class="math inline">\(p\)</span>?</strong></p>
    <p>Yes, absolutely. The standard inner product on <span
    class="math inline">\(E^n\)</span> induces a natural inner product
    on the tangent space <span class="math inline">\(T_pM\)</span> of
    the hypersurface <span class="math inline">\(M\)</span>. Since <span
    class="math inline">\(T_pM\)</span> is a subspace of <span
    class="math inline">\(T_pE^n\)</span>, we can simply restrict the
    inner product on <span class="math inline">\(E^n\)</span> to vectors
    in <span class="math inline">\(T_pM\)</span>. This is well-defined
    because the inner product of two vectors in <span
    class="math inline">\(T_pM\)</span> (which are also vectors in <span
    class="math inline">\(T_pE^n\)</span>) is just a scalar.</p>
    <p>More formally, let <span class="math inline">\(\langle \cdot,
    \cdot \rangle_{E^n}\)</span> denote the standard inner product on
    <span class="math inline">\(E^n\)</span>. We define the inner
    product <span class="math inline">\(\langle \cdot, \cdot
    \rangle_{M}\)</span> on <span class="math inline">\(T_pM\)</span> as
    follows:</p>
    <p>For any <span class="math inline">\(u, v \in T_pM\)</span>,</p>
    <p><span class="math display">\[\langle u, v \rangle_M = \langle u,
    v \rangle_{E^n}.\]</span></p>
    <p>Since <span class="math inline">\(u\)</span> and <span
    class="math inline">\(v\)</span> are also vectors in <span
    class="math inline">\(T_pE^n\)</span>, the right-hand side is
    well-defined and gives a scalar. This restricted inner product
    inherits all the properties of the inner product on <span
    class="math inline">\(E^n\)</span>, such as bilinearity, symmetry,
    and positive-definiteness. It’s called the <em>induced metric</em>
    or the <em>first fundamental form</em> on <span
    class="math inline">\(M\)</span>. This induced metric is what allows
    us to measure lengths of tangent vectors and angles between them,
    effectively giving <span class="math inline">\(M\)</span> its own
    geometric structure inherited from the ambient space <span
    class="math inline">\(E^n\)</span>.</p>
    <p><strong>If we use charts or local coordinates adapted to <span
    class="math inline">\(M\)</span>, can <span
    class="math inline">\(\langle \cdot, \cdot \rangle_M\)</span> be
    defined without referring to the ambient space?</strong></p>
    <p>Yes, you can define the induced metric on <span
    class="math inline">\(M\)</span> using local coordinates without
    explicitly referring back to the ambient space <span
    class="math inline">\(E^n\)</span>. Here’s how:</p>
    <ol type="1">
    <li><p><strong>Local Coordinates:</strong> Let <span
    class="math inline">\((U, \phi)\)</span> be a chart on <span
    class="math inline">\(M\)</span> around <span
    class="math inline">\(p\)</span>, where <span
    class="math inline">\(U\)</span> is an open set in <span
    class="math inline">\(M\)</span> containing <span
    class="math inline">\(p\)</span> and <span
    class="math inline">\(\phi: U \to \mathbb{R}^{n-1}\)</span> is a
    diffeomorphism onto an open set in <span
    class="math inline">\(\mathbb{R}^{n-1}\)</span> (since <span
    class="math inline">\(M\)</span> is a hypersurface in <span
    class="math inline">\(E^n\)</span>). Let <span
    class="math inline">\(x^1, \dots, x^{n-1}\)</span> be the local
    coordinates given by <span
    class="math inline">\(\phi\)</span>.</p></li>
    <li><p><strong>Coordinate Basis:</strong> At each point <span
    class="math inline">\(q \in U\)</span>, the tangent space <span
    class="math inline">\(T_qM\)</span> has a basis given by the
    coordinate vectors <span class="math inline">\(\partial/\partial
    x^1|_q, \dots, \partial/\partial x^{n-1}|_q\)</span>.</p></li>
    <li><p><strong>Metric Coefficients:</strong> The metric tensor <span
    class="math inline">\(g\)</span> on <span
    class="math inline">\(M\)</span> is represented in local coordinates
    by its components <span class="math inline">\(g_{ij}\)</span>. These
    components are defined as: <span class="math display">\[g_{ij}(q) =
    \left\langle \frac{\partial}{\partial x^i}\bigg|_q,
    \frac{\partial}{\partial x^j}\bigg|_q \right\rangle_M\]</span> for
    <span class="math inline">\(i, j = 1, \dots, n-1\)</span>.</p></li>
    <li><p><strong>Inner Product in Coordinates:</strong> Now, given two
    tangent vectors <span class="math inline">\(u, v \in T_qM\)</span>,
    we can express them in the coordinate basis: <span
    class="math display">\[u = \sum_{i=1}^{n-1} u^i
    \frac{\partial}{\partial x^i}\bigg|_q, \qquad v = \sum_{j=1}^{n-1}
    v^j \frac{\partial}{\partial x^j}\bigg|_q\]</span> The inner product
    of <span class="math inline">\(u\)</span> and <span
    class="math inline">\(v\)</span> is then given by <span
    class="math display">\[\langle u, v \rangle_M = \sum_{i=1}^{n-1}
    \sum_{j=1}^{n-1} u^i v^j g_{ij}(q).\]</span></p></li>
    </ol>
    <p>So, once you have the metric coefficients <span
    class="math inline">\(g_{ij}\)</span>, you can compute inner
    products entirely within the local coordinate system without needing
    to refer to the ambient space <span
    class="math inline">\(E^n\)</span>. The <span
    class="math inline">\(g_{ij}\)</span> themselves encode how the
    hypersurface is embedded in <span
    class="math inline">\(E^n\)</span>, but once you have them, the
    intrinsic geometry of <span class="math inline">\(M\)</span> is
    completely determined by them.</p>
    <p>In other words, you can perform geometric calculations on <span
    class="math inline">\(M\)</span> using only these <span
    class="math inline">\(g_{ij}\)</span>. You don’t need to think about
    the fact that <span class="math inline">\(M\)</span> “lives” inside
    <span class="math inline">\(E^n\)</span> to determine how <span
    class="math inline">\(M\)</span> curves. This is a core idea of
    intrinsic geometry.</p>
    <h1 id="shape-operator-2">Shape Operator 2</h1>
    <p><strong>For the setup above, the shape operator <span
    class="math inline">\(S_{N_p}\)</span> is adjoint with respect to
    <span class="math inline">\(\langle \cdot, \cdot \rangle_p\)</span>.
    What does this mean?</strong></p>
    <p>The statement that the shape operator <span
    class="math inline">\(S_{N_p}\)</span> at a point <span
    class="math inline">\(p\)</span> on the hypersurface <span
    class="math inline">\(M\)</span> is self-adjoint with respect to the
    inner product <span class="math inline">\(\langle \cdot, \cdot
    \rangle_p\)</span> (which is the induced metric on <span
    class="math inline">\(T_pM\)</span>) means the following:</p>
    <p>For any two tangent vectors <span class="math inline">\(u, v \in
    T_pM\)</span>,</p>
    <p><span class="math display">\[\langle S_{N_p}(u), v \rangle_p =
    \langle u, S_{N_p}(v) \rangle_p\]</span></p>
    <p>In other words, the shape operator is symmetric with respect to
    the inner product. This is a crucial property of the shape operator
    and has important consequences for the study of the curvature of
    hypersurfaces.</p>
    <p>Here’s why this is significant:</p>
    <ol type="1">
    <li><p><strong>Real Eigenvalues and Orthogonal
    Eigenvectors:</strong> Because <span
    class="math inline">\(S_{N_p}\)</span> is a self-adjoint operator on
    a finite-dimensional vector space (<span
    class="math inline">\(T_pM\)</span>) with an inner product, it is
    guaranteed to have real eigenvalues and an orthonormal basis of
    eigenvectors. These eigenvalues are called the <em>principal
    curvatures</em> of <span class="math inline">\(M\)</span> at <span
    class="math inline">\(p\)</span>, and the eigenvectors are the
    <em>principal directions</em>.</p></li>
    <li><p><strong>Diagonalization:</strong> The self-adjointness of
    <span class="math inline">\(S_{N_p}\)</span> means that in the basis
    of principal directions, the matrix representation of <span
    class="math inline">\(S_{N_p}\)</span> is diagonal, with the
    principal curvatures along the diagonal.</p></li>
    <li><p><strong>Geometric Interpretation:</strong> The principal
    curvatures measure the amount of bending of the hypersurface in the
    principal directions. The fact that they are real and that we can
    find an orthonormal basis of principal directions means that we can
    decompose the curvature of <span class="math inline">\(M\)</span> at
    <span class="math inline">\(p\)</span> into these orthogonal
    components.</p></li>
    </ol>
    <p>So, the self-adjointness of the shape operator is a fundamental
    property that makes it possible to analyze the curvature of
    hypersurfaces in a very convenient and geometrically meaningful
    way.</p>
    <p><strong>With a chart adapted to <span
    class="math inline">\(M\)</span>, does this mean that the
    representation of <span class="math inline">\(S_{N_p}\)</span> in
    the adapted chart local coordinates is a symmetric
    matrix?</strong></p>
    <p>Yes, precisely. If you choose local coordinates <span
    class="math inline">\(x^1, \dots, x^{n-1}\)</span> adapted to the
    hypersurface <span class="math inline">\(M\)</span> around a point
    <span class="math inline">\(p\)</span>, and you represent the shape
    operator <span class="math inline">\(S_{N_p}\)</span> as a matrix
    with respect to the basis <span
    class="math inline">\(\frac{\partial}{\partial x^1}|_p, ...,
    \frac{\partial}{\partial x^{n-1}}|_p\)</span> of <span
    class="math inline">\(T_pM\)</span>, then the resulting matrix will
    be a symmetric matrix.</p>
    <p>Here’s why:</p>
    <p>The components of the matrix representation of <span
    class="math inline">\(S_{N_p}\)</span> are given by:</p>
    <p><span class="math display">\[(S_{N_p})_{ij} = \left\langle
    S_{N_p}\left(\frac{\partial}{\partial x^i}|_p\right),
    \frac{\partial}{\partial x^j}|_p \right\rangle_p\]</span></p>
    <p>Since <span class="math inline">\(S_{N_p}\)</span> is
    self-adjoint, we have:</p>
    <p><span class="math display">\[\left\langle
    S_{N_p}\left(\frac{\partial}{\partial x^i}|_p\right),
    \frac{\partial}{\partial x^j}|_p \right\rangle_p = \left\langle
    \frac{\partial}{\partial x^i}|_p,
    S_{N_p}\left(\frac{\partial}{\partial x^j}|_p\right)
    \right\rangle_p\]</span></p>
    <p>This means <span class="math inline">\((S_{N_p})_{ij} =
    (S_{N_p})_{ji}\)</span>, which is the definition of a symmetric
    matrix.</p>
    <p>Therefore, the self-adjointness of <span
    class="math inline">\(S_{N_p}\)</span> directly translates to the
    symmetry of its matrix representation in a coordinate basis adapted
    to <span class="math inline">\(M\)</span>. This is why you can
    always diagonalize the matrix of the shape operator using an
    orthogonal matrix, as is guaranteed for any real symmetric
    matrix.</p>
    <p><strong>Provide more detail on the expression for the <span
    class="math inline">\((i,j)\)</span>-th component of the
    matrix.</strong></p>
    <p>Let’s break down the expression for the <span
    class="math inline">\((i, j)\)</span>-th component of the matrix
    representation of the shape operator <span
    class="math inline">\(S_{N_p}\)</span> in more detail.</p>
    <ol type="1">
    <li><p><strong>Coordinate Basis:</strong> We have a chart <span
    class="math inline">\((U, \phi)\)</span> adapted to the hypersurface
    <span class="math inline">\(M\)</span> around the point <span
    class="math inline">\(p\)</span>. This gives us local coordinates
    <span class="math inline">\(x^1, \dots, x^{n-1}\)</span>, and a
    corresponding basis for the tangent space <span
    class="math inline">\(T_pM\)</span>: <span
    class="math inline">\(\frac{\partial}{\partial x^1}|_p, \dots,
    \frac{\partial}{\partial x^{n-1}}|_p\)</span>.</p></li>
    <li><p><strong>Shape Operator:</strong> The shape operator <span
    class="math inline">\(S_{N_p}: T_pM \to T_pM\)</span> is defined as
    <span class="math inline">\(S_{N_p}(v) = -\nabla_v N\)</span>, where
    <span class="math inline">\(N\)</span> is a unit normal vector field
    to <span class="math inline">\(M\)</span>. Remember, this covariant
    derivative <span class="math inline">\(\nabla_v N\)</span> is taken
    in the ambient space <span class="math inline">\(E^n\)</span>, but
    the result lies in <span
    class="math inline">\(T_pM\)</span>.</p></li>
    <li><p><strong>Matrix Components:</strong> To represent <span
    class="math inline">\(S_{N_p}\)</span> as a matrix, we need to see
    how it acts on the basis vectors. The <span
    class="math inline">\((i, j)\)</span>-th component of the matrix is
    given by the inner product of the shape operator applied to the
    <span class="math inline">\(i\)</span>-th basis vector with the
    <span class="math inline">\(j\)</span>-th basis vector:</p>
    <p><span class="math display">\[(S_{N_p})_{ij} = \left\langle
    S_{N_p}\left(\frac{\partial}{\partial x^i}|_p\right),
    \frac{\partial}{\partial x^j}|_p \right\rangle_p = \left\langle
    -\nabla_{\frac{\partial}{\partial x^i}|_p} N,
    \frac{\partial}{\partial x^j}|_p \right\rangle_p\]</span></p></li>
    <li><p><strong>Calculating the Covariant Derivative:</strong> The
    term <span class="math inline">\(\nabla_{\frac{\partial}{\partial
    x^i}|_p} N\)</span> represents how the normal vector field <span
    class="math inline">\(N\)</span> changes as you move along the
    coordinate curve <span class="math inline">\(x^i\)</span>. This is
    calculated in the ambient space <span
    class="math inline">\(E^n\)</span>, and then projected onto <span
    class="math inline">\(T_pM\)</span>.</p></li>
    <li><p><strong>Induced Metric:</strong> The inner product <span
    class="math inline">\(\langle \cdot, \cdot \rangle_p\)</span> is the
    induced metric on <span class="math inline">\(T_pM\)</span>,
    inherited from the standard inner product in <span
    class="math inline">\(E^n\)</span>.</p></li>
    <li><p><strong>Putting it Together:</strong> So, to calculate <span
    class="math inline">\((S_{N_p})_{ij}\)</span>, you would:</p>
    <ul>
    <li>Take the covariant derivative of the normal vector field <span
    class="math inline">\(N\)</span> in the direction of <span
    class="math inline">\(\frac{\partial}{\partial x^i}|_p\)</span>.
    This involves calculating the directional derivative of the
    components of <span class="math inline">\(N\)</span> in the ambient
    space and then projecting the result onto <span
    class="math inline">\(T_pM\)</span>.</li>
    <li>Take the inner product (using the induced metric) of the
    resulting tangent vector with <span
    class="math inline">\(\frac{\partial}{\partial
    x^j}|_p\)</span>.</li>
    </ul></li>
    </ol>
    <p>This process gives you the <span class="math inline">\((i,
    j)\)</span>-th component of the matrix representation of the shape
    operator in the given coordinate basis. Because <span
    class="math inline">\(S_{N_p}\)</span> is self-adjoint, the
    resulting matrix will always be symmetric.</p>
    <p><strong>I have forgotten my linear algebra. Why in Step 3 do you
    need to take the inner product?</strong></p>
    <p>The reason we take the inner product in Step 3 is to extract the
    <em>components</em> of the vector <span
    class="math inline">\(S_{N_p}(\frac{\partial}{\partial
    x^i}|_p)\)</span> with respect to the basis vectors. Let’s break
    this down with a general linear algebra analogy.</p>
    <p>Suppose you have a linear transformation <span
    class="math inline">\(T: V \to V\)</span>, where <span
    class="math inline">\(V\)</span> is a vector space with an inner
    product <span class="math inline">\(\langle \cdot, \cdot
    \rangle\)</span>. Let <span class="math inline">\(\{e_1, \dots,
    e_n\}\)</span> be an orthonormal basis for <span
    class="math inline">\(V\)</span>. We want to represent <span
    class="math inline">\(T\)</span> as a matrix <span
    class="math inline">\(A\)</span> with respect to this basis.</p>
    <p>The <span class="math inline">\(j\)</span>-th column of the
    matrix <span class="math inline">\(A\)</span> represents the vector
    <span class="math inline">\(T(e_j)\)</span> expressed in the basis
    <span class="math inline">\(\{e_1, \dots, e_n\}\)</span>. So, we
    have:</p>
    <p><span class="math display">\[T(e_j) = \sum_{i=1}^n A_{ij}
    e_i\]</span></p>
    <p>Now, to find the component <span
    class="math inline">\(A_{ij}\)</span>, we take the inner product of
    both sides with <span class="math inline">\(e_i\)</span>:</p>
    <p><span class="math display">\[\langle T(e_j), e_i \rangle =
    \left\langle \sum_{k=1}^n A_{kj} e_k, e_i \right\rangle =
    \sum_{k=1}^n A_{kj} \langle e_k, e_i \rangle\]</span></p>
    <p>Since the basis is orthonormal, <span
    class="math inline">\(\langle e_k, e_i \rangle =
    \delta_{ki}\)</span> (Kronecker delta, which is 1 if <span
    class="math inline">\(k=i\)</span> and 0 otherwise). Therefore,</p>
    <p><span class="math display">\[\langle T(e_j), e_i \rangle =
    A_{ij}\]</span></p>
    <p>So, the inner product <span class="math inline">\(\langle T(e_j),
    e_i \rangle\)</span> gives us exactly the <span
    class="math inline">\((i, j)\)</span>-th entry of the matrix
    representation of <span class="math inline">\(T\)</span>.</p>
    <p>In the case of the shape operator, <span
    class="math inline">\(T\)</span> is <span
    class="math inline">\(S_{N_p}\)</span>, <span
    class="math inline">\(V\)</span> is <span
    class="math inline">\(T_pM\)</span>, the basis vectors are <span
    class="math inline">\(\frac{\partial}{\partial x^i}|_p\)</span>, and
    the inner product is the induced metric. Even if the basis isn’t
    orthonormal (as is usually the case with coordinate bases on
    manifolds), the principle remains the same. The inner product allows
    you to project the transformed vector <span
    class="math inline">\(S_{N_p}(\frac{\partial}{\partial
    x^i}|_p)\)</span> onto the basis vector <span
    class="math inline">\(\frac{\partial}{\partial x^j}|_p\)</span> to
    extract the corresponding matrix component <span
    class="math inline">\((S_{N_p})_{ij}\)</span>.</p>
  </article>
</body>
</html>